{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset(datasetPath):\n",
    "\n",
    "  # List for storing data\n",
    "  data = []\n",
    "  \n",
    "  # List for storing labels\n",
    "  labels = []\n",
    "  \n",
    "  for row in open(datasetPath): #Openfile and start reading each row\n",
    "    #Split the row at every comma\n",
    "    row = row.split(\",\")\n",
    "    \n",
    "    #row[0] contains label\n",
    "    label = int(row[0])\n",
    "    \n",
    "    #Other all collumns contains pixel values make a saperate array for that\n",
    "    image = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
    "    \n",
    "    #Reshaping image to 28 x 28 pixels\n",
    "    image = image.reshape((32, 32))\n",
    "    \n",
    "    #append image to data\n",
    "    data.append(image)\n",
    "    \n",
    "    #append label to labels\n",
    "    labels.append(label)\n",
    "    \n",
    "  #Converting data to numpy array of type float32\n",
    "  data = np.array(data, dtype='float32')\n",
    "  \n",
    "  #Converting labels to type int\n",
    "  labels = np.array(labels, dtype=\"int\")\n",
    "  \n",
    "  return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Data, Labels) = load_dataset(\"../data/uaset_without_columns.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Data, Labels) = load_dataset(\"../data/uaset_extended_lower_case_size_reduction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Each image in the A-Z and MNIST digts datasets are 28x28 pixels;\n",
    "# However, the architecture we're using is designed for 32x32 images,\n",
    "# So we need to resize them to 32x32\n",
    "\n",
    "Data = [cv2.resize(image, (32, 32)) for image in Data]\n",
    "Data = np.array(Data, dtype=\"float32\")\n",
    "\n",
    "# add a channel dimension to every image in the dataset and scale the\n",
    "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
    "\n",
    "Data = np.expand_dims(Data, axis=-1)\n",
    "Data /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "le = LabelBinarizer()\n",
    "Labels = le.fit_transform(Labels)\n",
    "\n",
    "counts = Labels.sum(axis=0)\n",
    "\n",
    "# account for skew in the labeled data\n",
    "classTotals = Labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "  classWeight[i] = classTotals.max() / classTotals[i]\n",
    "  \n",
    "(trainX, testX, trainY, testY) = train_test_split(Data,\n",
    "\tLabels, test_size=0.30, stratify=Labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "rotation_range=5,\n",
    "zoom_range=0.05,\n",
    "width_shift_range=0.10,\n",
    "height_shift_range=0.10,\n",
    "shear_range=0.1,\n",
    "horizontal_flip=False,\n",
    "fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class ResNet:\n",
    "\t@staticmethod\n",
    "\tdef residual_module(data, K, stride, chanDim, red=False,\n",
    "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "\t\t# the shortcut branch of the ResNet module should be\n",
    "\t\t# initialize as the input (identity) data\n",
    "\t\tshortcut = data\n",
    "\n",
    "\t\t# the first block of the ResNet module are the 1x1 CONVs\n",
    "\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(data)\n",
    "\t\tact1 = Activation(\"relu\")(bn1)\n",
    "\t\tconv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "\t\t# the second block of the ResNet module are the 3x3 CONVs\n",
    "\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(conv1)\n",
    "\t\tact2 = Activation(\"relu\")(bn2)\n",
    "\t\tconv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n",
    "\t\t\tpadding=\"same\", use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act2)\n",
    "\n",
    "\t\t# the third block of the ResNet module is another set of 1x1\n",
    "\t\t# CONVs\n",
    "\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(conv2)\n",
    "\t\tact3 = Activation(\"relu\")(bn3)\n",
    "\t\tconv3 = Conv2D(K, (1, 1), use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act3)\n",
    "\n",
    "\t\t# if we are to reduce the spatial size, apply a CONV layer to\n",
    "\t\t# the shortcut\n",
    "\t\tif red:\n",
    "\t\t\tshortcut = Conv2D(K, (1, 1), strides=stride,\n",
    "\t\t\t\tuse_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "\t\t# add together the shortcut and the final CONV\n",
    "\t\tx = add([conv3, shortcut])\n",
    "\n",
    "\t\t# return the addition as the output of the ResNet module\n",
    "\t\treturn x\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes, stages, filters,\n",
    "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9, dataset=\"cifar\"):\n",
    "\t\t# initialize the input shape to be \"channels last\" and the\n",
    "\t\t# channels dimension itself\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "\n",
    "\t\t# set the input and apply BN\n",
    "\t\tinputs = Input(shape=inputShape)\n",
    "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(inputs)\n",
    "\n",
    "\t\t# check if we are utilizing the CIFAR dataset\n",
    "\t\tif dataset == \"cifar\":\n",
    "\t\t\t# apply a single CONV layer\n",
    "\t\t\tx = Conv2D(filters[0], (3, 3), use_bias=False,\n",
    "\t\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "\n",
    "\t\t# check to see if we are using the Tiny ImageNet dataset\n",
    "\t\telif dataset == \"tiny_imagenet\":\n",
    "\t\t\t# apply CONV => BN => ACT => POOL to reduce spatial size\n",
    "\t\t\tx = Conv2D(filters[0], (5, 5), use_bias=False,\n",
    "\t\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "\t\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\t\tmomentum=bnMom)(x)\n",
    "\t\t\tx = Activation(\"relu\")(x)\n",
    "\t\t\tx = ZeroPadding2D((1, 1))(x)\n",
    "\t\t\tx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "\t\t# loop over the number of stages\n",
    "\t\tfor i in range(0, len(stages)):\n",
    "\t\t\t# initialize the stride, then apply a residual module\n",
    "\t\t\t# used to reduce the spatial size of the input volume\n",
    "\t\t\tstride = (1, 1) if i == 0 else (2, 2)\n",
    "\t\t\tx = ResNet.residual_module(x, filters[i + 1], stride,\n",
    "\t\t\t\tchanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "\t\t\t# loop over the number of layers in the stage\n",
    "\t\t\tfor j in range(0, stages[i] - 1):\n",
    "\t\t\t\t# apply a ResNet module\n",
    "\t\t\t\tx = ResNet.residual_module(x, filters[i + 1],\n",
    "\t\t\t\t\t(1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "\t\t# apply BN => ACT => POOL\n",
    "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(x)\n",
    "\t\tx = Activation(\"relu\")(x)\n",
    "\t\tx = AveragePooling2D((8, 8))(x)\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tx = Flatten()(x)\n",
    "\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "\t\tx = Activation(\"softmax\")(x)\n",
    "\n",
    "\t\t# create the model\n",
    "\t\tmodel = Model(inputs, x, name=\"resnet\")\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 120\n",
    "INIT_LR = 1\n",
    "BS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3),\n",
    "\t(64, 64, 128, 256), reg=0.0005)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 1)    4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   576         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   1024        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2304        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   1024        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   4096        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   1024        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2304        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1024        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2304        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 64)   1024        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           conv2d_10[0][0]                  \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 32)   2048        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9216        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 128)  4096        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  8192        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 128)  0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 32)   4096        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 128)  4096        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           conv2d_17[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 32)   4096        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 32)   9216        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 128)  4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 128)  0           conv2d_20[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   8192        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 64)     36864       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 256)    16384       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 256)    32768       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 256)    0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 256)    1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 64)     16384       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 64)     36864       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 256)    16384       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 256)    0           conv2d_27[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 64)     16384       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 64)     36864       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 256)    16384       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 256)    0           conv2d_30[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 256)    0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 57)           14649       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 57)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 332,541\n",
      "Trainable params: 328,379\n",
      "Non-trainable params: 4,162\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Додайте колбеки\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=12, verbose=1, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.001, verbose=1)\n",
    "\n",
    "callbacks_list = [early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 2.0139 - accuracy: 0.6280 - val_loss: 0.8515 - val_accuracy: 0.8480 - lr: 1.0000\n",
      "Epoch 2/120\n",
      "742/742 [==============================] - 64s 86ms/step - loss: 0.8615 - accuracy: 0.8798 - val_loss: 0.6406 - val_accuracy: 0.8989 - lr: 1.0000\n",
      "Epoch 3/120\n",
      "742/742 [==============================] - 64s 86ms/step - loss: 0.7476 - accuracy: 0.9018 - val_loss: 0.6002 - val_accuracy: 0.9103 - lr: 1.0000\n",
      "Epoch 4/120\n",
      "742/742 [==============================] - 64s 86ms/step - loss: 0.6928 - accuracy: 0.9127 - val_loss: 0.5812 - val_accuracy: 0.9129 - lr: 1.0000\n",
      "Epoch 5/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.6596 - accuracy: 0.9185 - val_loss: 0.5415 - val_accuracy: 0.9232 - lr: 1.0000\n",
      "Epoch 6/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.6378 - accuracy: 0.9218 - val_loss: 0.5245 - val_accuracy: 0.9255 - lr: 1.0000\n",
      "Epoch 7/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.6215 - accuracy: 0.9242 - val_loss: 0.5197 - val_accuracy: 0.9246 - lr: 1.0000\n",
      "Epoch 8/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.6105 - accuracy: 0.9256 - val_loss: 0.5184 - val_accuracy: 0.9250 - lr: 1.0000\n",
      "Epoch 9/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.5985 - accuracy: 0.9281 - val_loss: 0.5020 - val_accuracy: 0.9287 - lr: 1.0000\n",
      "Epoch 10/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.5884 - accuracy: 0.9286 - val_loss: 0.4977 - val_accuracy: 0.9298 - lr: 1.0000\n",
      "Epoch 11/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5835 - accuracy: 0.9309 - val_loss: 0.4909 - val_accuracy: 0.9315 - lr: 1.0000\n",
      "Epoch 12/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5744 - accuracy: 0.9309 - val_loss: 0.4869 - val_accuracy: 0.9321 - lr: 1.0000\n",
      "Epoch 13/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5673 - accuracy: 0.9323 - val_loss: 0.4872 - val_accuracy: 0.9320 - lr: 1.0000\n",
      "Epoch 14/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.5631 - accuracy: 0.9326 - val_loss: 0.4718 - val_accuracy: 0.9342 - lr: 1.0000\n",
      "Epoch 15/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.5575 - accuracy: 0.9328 - val_loss: 0.4671 - val_accuracy: 0.9359 - lr: 1.0000\n",
      "Epoch 16/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.5560 - accuracy: 0.9323 - val_loss: 0.4723 - val_accuracy: 0.9338 - lr: 1.0000\n",
      "Epoch 17/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5482 - accuracy: 0.9341 - val_loss: 0.4612 - val_accuracy: 0.9364 - lr: 1.0000\n",
      "Epoch 18/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.5446 - accuracy: 0.9343 - val_loss: 0.4607 - val_accuracy: 0.9359 - lr: 1.0000\n",
      "Epoch 19/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.5417 - accuracy: 0.9343 - val_loss: 0.4622 - val_accuracy: 0.9345 - lr: 1.0000\n",
      "Epoch 20/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5355 - accuracy: 0.9355 - val_loss: 0.4585 - val_accuracy: 0.9348 - lr: 1.0000\n",
      "Epoch 21/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5361 - accuracy: 0.9369 - val_loss: 0.4551 - val_accuracy: 0.9352 - lr: 1.0000\n",
      "Epoch 22/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.5313 - accuracy: 0.9359 - val_loss: 0.4558 - val_accuracy: 0.9353 - lr: 1.0000\n",
      "Epoch 23/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5283 - accuracy: 0.9369 - val_loss: 0.4525 - val_accuracy: 0.9368 - lr: 1.0000\n",
      "Epoch 24/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5240 - accuracy: 0.9383 - val_loss: 0.4461 - val_accuracy: 0.9371 - lr: 1.0000\n",
      "Epoch 25/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.5240 - accuracy: 0.9373 - val_loss: 0.4438 - val_accuracy: 0.9385 - lr: 1.0000\n",
      "Epoch 26/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5198 - accuracy: 0.9379 - val_loss: 0.4479 - val_accuracy: 0.9351 - lr: 1.0000\n",
      "Epoch 27/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.5207 - accuracy: 0.9386 - val_loss: 0.4468 - val_accuracy: 0.9358 - lr: 1.0000\n",
      "Epoch 28/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.5150 - accuracy: 0.9374 - val_loss: 0.4417 - val_accuracy: 0.9371 - lr: 1.0000\n",
      "Epoch 29/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.5144 - accuracy: 0.9387 - val_loss: 0.4463 - val_accuracy: 0.9362 - lr: 1.0000\n",
      "Epoch 30/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.5130 - accuracy: 0.9383 - val_loss: 0.4373 - val_accuracy: 0.9377 - lr: 1.0000\n",
      "Epoch 31/120\n",
      "742/742 [==============================] - 67s 91ms/step - loss: 0.5109 - accuracy: 0.9401 - val_loss: 0.4446 - val_accuracy: 0.9364 - lr: 1.0000\n",
      "Epoch 32/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.5104 - accuracy: 0.9392 - val_loss: 0.4352 - val_accuracy: 0.9396 - lr: 1.0000\n",
      "Epoch 33/120\n",
      "742/742 [==============================] - 68s 91ms/step - loss: 0.5115 - accuracy: 0.9384 - val_loss: 0.4308 - val_accuracy: 0.9391 - lr: 1.0000\n",
      "Epoch 34/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.5039 - accuracy: 0.9402 - val_loss: 0.4301 - val_accuracy: 0.9384 - lr: 1.0000\n",
      "Epoch 35/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.5036 - accuracy: 0.9402 - val_loss: 0.4373 - val_accuracy: 0.9364 - lr: 1.0000\n",
      "Epoch 36/120\n",
      "742/742 [==============================] - 67s 90ms/step - loss: 0.5040 - accuracy: 0.9399 - val_loss: 0.4351 - val_accuracy: 0.9370 - lr: 1.0000\n",
      "Epoch 37/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.4997 - accuracy: 0.9407 - val_loss: 0.4302 - val_accuracy: 0.9382 - lr: 1.0000\n",
      "Epoch 38/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.5026 - accuracy: 0.9398 - val_loss: 0.4326 - val_accuracy: 0.9383 - lr: 1.0000\n",
      "Epoch 39/120\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.9406\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.4980 - accuracy: 0.9406 - val_loss: 0.4317 - val_accuracy: 0.9377 - lr: 1.0000\n",
      "Epoch 40/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.4956 - accuracy: 0.9409 - val_loss: 0.4306 - val_accuracy: 0.9379 - lr: 0.0000e+00\n",
      "Epoch 41/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4949 - accuracy: 0.9410 - val_loss: 0.4326 - val_accuracy: 0.9374 - lr: 0.0000e+00\n",
      "Epoch 42/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4945 - accuracy: 0.9408 - val_loss: 0.4345 - val_accuracy: 0.9365 - lr: 0.0000e+00\n",
      "Epoch 43/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4962 - accuracy: 0.9404 - val_loss: 0.4301 - val_accuracy: 0.9381 - lr: 0.0000e+00\n",
      "Epoch 44/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4963 - accuracy: 0.9408 - val_loss: 0.4303 - val_accuracy: 0.9381 - lr: 0.0000e+00\n",
      "Epoch 45/120\n",
      "742/742 [==============================] - 65s 87ms/step - loss: 0.4964 - accuracy: 0.9397 - val_loss: 0.4292 - val_accuracy: 0.9385 - lr: 0.0000e+00\n",
      "Epoch 46/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4960 - accuracy: 0.9403 - val_loss: 0.4314 - val_accuracy: 0.9378 - lr: 0.0000e+00\n",
      "Epoch 47/120\n",
      "742/742 [==============================] - 64s 87ms/step - loss: 0.4961 - accuracy: 0.9409 - val_loss: 0.4296 - val_accuracy: 0.9380 - lr: 0.0000e+00\n",
      "Epoch 48/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4970 - accuracy: 0.9406 - val_loss: 0.4315 - val_accuracy: 0.9369 - lr: 0.0000e+00\n",
      "Epoch 49/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4951 - accuracy: 0.9407 - val_loss: 0.4297 - val_accuracy: 0.9376 - lr: 0.0000e+00\n",
      "Epoch 50/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4954 - accuracy: 0.9397 - val_loss: 0.4285 - val_accuracy: 0.9380 - lr: 0.0000e+00\n",
      "Epoch 51/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4965 - accuracy: 0.9405 - val_loss: 0.4310 - val_accuracy: 0.9376 - lr: 0.0000e+00\n",
      "Epoch 52/120\n",
      "742/742 [==============================] - 66s 88ms/step - loss: 0.4943 - accuracy: 0.9412 - val_loss: 0.4318 - val_accuracy: 0.9365 - lr: 0.0000e+00\n",
      "Epoch 53/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4972 - accuracy: 0.9407 - val_loss: 0.4300 - val_accuracy: 0.9374 - lr: 0.0000e+00\n",
      "Epoch 54/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4971 - accuracy: 0.9402 - val_loss: 0.4309 - val_accuracy: 0.9380 - lr: 0.0000e+00\n",
      "Epoch 55/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4954 - accuracy: 0.9407 - val_loss: 0.4313 - val_accuracy: 0.9363 - lr: 0.0000e+00\n",
      "Epoch 56/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4974 - accuracy: 0.9403 - val_loss: 0.4303 - val_accuracy: 0.9381 - lr: 0.0000e+00\n",
      "Epoch 57/120\n",
      "742/742 [==============================] - 67s 90ms/step - loss: 0.4971 - accuracy: 0.9395 - val_loss: 0.4287 - val_accuracy: 0.9388 - lr: 0.0000e+00\n",
      "Epoch 58/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4988 - accuracy: 0.9392 - val_loss: 0.4305 - val_accuracy: 0.9383 - lr: 0.0000e+00\n",
      "Epoch 59/120\n",
      "742/742 [==============================] - 65s 88ms/step - loss: 0.4957 - accuracy: 0.9413 - val_loss: 0.4313 - val_accuracy: 0.9379 - lr: 0.0000e+00\n",
      "Epoch 60/120\n",
      "742/742 [==============================] - 66s 88ms/step - loss: 0.4961 - accuracy: 0.9395 - val_loss: 0.4280 - val_accuracy: 0.9387 - lr: 0.0000e+00\n",
      "Epoch 61/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4948 - accuracy: 0.9411 - val_loss: 0.4310 - val_accuracy: 0.9373 - lr: 0.0000e+00\n",
      "Epoch 62/120\n",
      "742/742 [==============================] - 66s 88ms/step - loss: 0.4950 - accuracy: 0.9394 - val_loss: 0.4323 - val_accuracy: 0.9373 - lr: 0.0000e+00\n",
      "Epoch 63/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4972 - accuracy: 0.9394 - val_loss: 0.4309 - val_accuracy: 0.9373 - lr: 0.0000e+00\n",
      "Epoch 64/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4964 - accuracy: 0.9408 - val_loss: 0.4312 - val_accuracy: 0.9378 - lr: 0.0000e+00\n",
      "Epoch 65/120\n",
      "742/742 [==============================] - 68s 91ms/step - loss: 0.4956 - accuracy: 0.9419 - val_loss: 0.4317 - val_accuracy: 0.9369 - lr: 0.0000e+00\n",
      "Epoch 66/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4952 - accuracy: 0.9410 - val_loss: 0.4317 - val_accuracy: 0.9372 - lr: 0.0000e+00\n",
      "Epoch 67/120\n",
      "742/742 [==============================] - 66s 88ms/step - loss: 0.4969 - accuracy: 0.9395 - val_loss: 0.4310 - val_accuracy: 0.9371 - lr: 0.0000e+00\n",
      "Epoch 68/120\n",
      "742/742 [==============================] - 66s 88ms/step - loss: 0.4964 - accuracy: 0.9405 - val_loss: 0.4339 - val_accuracy: 0.9367 - lr: 0.0000e+00\n",
      "Epoch 69/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4980 - accuracy: 0.9411 - val_loss: 0.4315 - val_accuracy: 0.9368 - lr: 0.0000e+00\n",
      "Epoch 70/120\n",
      "742/742 [==============================] - 67s 90ms/step - loss: 0.4937 - accuracy: 0.9403 - val_loss: 0.4299 - val_accuracy: 0.9380 - lr: 0.0000e+00\n",
      "Epoch 71/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4956 - accuracy: 0.9399 - val_loss: 0.4313 - val_accuracy: 0.9376 - lr: 0.0000e+00\n",
      "Epoch 72/120\n",
      "742/742 [==============================] - 66s 89ms/step - loss: 0.4948 - accuracy: 0.9412 - val_loss: 0.4299 - val_accuracy: 0.9376 - lr: 0.0000e+00\n",
      "Epoch 00072: early stopping\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=classWeight,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAACA+UlEQVR4nO3dd3wUdf7H8ddszaYnhIROkI4UERARURQUUXMidvEAsQs2xFPOE0VPsfJTz8J5FvQEURGQs6CIgoooRbAi0kFaaOnJbnZ3fn9MshATIIRNloT38/EYdnd2ymdmE/aTz/f7nTFM0zQRERERqSNskQ5AREREJJyU3IiIiEidouRGRERE6hQlNyIiIlKnKLkRERGROkXJjYiIiNQpSm5ERESkTlFyIyIiInWKkhsRERGpU5TciETI8OHDSU9Pr9K6DzzwAIZhhDcgqZL58+djGAbz58+PdCgiUkLJjcifGIZRqelY/TIbPnw4sbGxkQ6jVnvhhRcwDIOePXtGOhSROskR6QBEjjb//e9/y7x+4403mDt3brn57du3P6L9/Oc//yEYDFZp3X/84x/cc889R7R/iZwpU6aQnp7O4sWLWbNmDa1atYp0SCJ1ipIbkT+56qqryrz+9ttvmTt3brn5f1ZQUEB0dHSl9+N0OqsUH4DD4cDh0K9vbbR+/Xq++eYbZsyYwQ033MCUKVO4//77Ix1WhfLz84mJiYl0GCKHTc1SIlXQt29fOnbsyLJlyzjttNOIjo7m73//OwDvv/8+5513Ho0aNcLtdtOyZUseeughAoFAmW38uc/Nhg0bMAyDJ598kpdeeomWLVvidrvp0aMHS5YsKbNuRX1uDMNg1KhRzJo1i44dO+J2uzn++OOZM2dOufjnz59P9+7diYqKomXLlvz73/8Oez+ed999l27duuHxeEhJSeGqq65iy5YtZZbZvn07V199NU2aNMHtdtOwYUMuuOACNmzYEFpm6dKlDBgwgJSUFDweDy1atGDEiBGH3H9lP4fSz/LXX3/ljDPOIDo6msaNG/P444+X2+Yff/zBoEGDiImJITU1lTvuuAOv13tY52XKlCkkJSVx3nnncfHFFzNlypQKl8vKyuKOO+4gPT0dt9tNkyZNGDp0KLt27QotU1RUxAMPPECbNm2IioqiYcOGDB48mLVr1wIH7g9U+rM2efLk0LzS5sa1a9dy7rnnEhcXx5AhQwD46quvuOSSS2jWrBlut5umTZtyxx13UFhYWC7u3377jUsvvZT69evj8Xho27Yt9957LwBffPEFhmEwc+bMcutNnToVwzBYtGjRYZ1PkYroTz+RKtq9ezcDBw7k8ssv56qrriItLQ2AyZMnExsby+jRo4mNjeXzzz9n3Lhx5OTk8MQTTxxyu1OnTiU3N5cbbrgBwzB4/PHHGTx4MOvWrTtktefrr79mxowZ3HzzzcTFxfHss89y0UUXsWnTJurVqwfA8uXLOeecc2jYsCHjx48nEAjw4IMPUr9+/SM/KSUmT57M1VdfTY8ePZgwYQI7duzgmWeeYeHChSxfvpzExEQALrroIn755RduueUW0tPTyczMZO7cuWzatCn0+uyzz6Z+/frcc889JCYmsmHDBmbMmFGpGCr7Oezdu5dzzjmHwYMHc+mllzJ9+nTuvvtuOnXqxMCBAwEoLCykX79+bNq0iVtvvZVGjRrx3//+l88///ywzs2UKVMYPHgwLpeLK664ghdffJElS5bQo0eP0DJ5eXn06dOHlStXMmLECE488UR27drF7Nmz+eOPP0hJSSEQCHD++eczb948Lr/8cm677TZyc3OZO3cuP//8My1btjysuAD8fj8DBgzg1FNP5cknnwxVIt99910KCgq46aabqFevHosXL+Zf//oXf/zxB++++25o/R9//JE+ffrgdDq5/vrrSU9PZ+3atfzvf//j4Ycfpm/fvjRt2pQpU6Zw4YUXljsvLVu2pFevXocdt0g5pogc1MiRI80//6qcfvrpJmBOmjSp3PIFBQXl5t1www1mdHS0WVRUFJo3bNgws3nz5qHX69evNwGzXr165p49e0Lz33//fRMw//e//4Xm3X///eViAkyXy2WuWbMmNO+HH34wAfNf//pXaF5GRoYZHR1tbtmyJTRv9erVpsPhKLfNigwbNsyMiYk54Ps+n89MTU01O3bsaBYWFobmf/DBByZgjhs3zjRN09y7d68JmE888cQBtzVz5kwTMJcsWXLIuP6ssp9D6Wf5xhtvhOZ5vV6zQYMG5kUXXRSa9/TTT5uA+c4774Tm5efnm61atTIB84svvjhkTEuXLjUBc+7cuaZpmmYwGDSbNGli3nbbbWWWGzdunAmYM2bMKLeNYDBomqZpvvrqqyZgTpw48YDLfPHFFxXGVvqz9tprr4XmDRs2zATMe+65p9z2KjqXEyZMMA3DMDdu3Biad9ppp5lxcXFl5u0fj2ma5tixY023221mZWWF5mVmZpoOh8O8//77y+1HpCrULCVSRW63m6uvvrrcfI/HE3qem5vLrl276NOnDwUFBfz222+H3O5ll11GUlJS6HWfPn0AWLdu3SHX7d+/f5m/2Dt37kx8fHxo3UAgwGeffcagQYNo1KhRaLlWrVqFKhRHaunSpWRmZnLzzTcTFRUVmn/eeefRrl07PvzwQ8A6Ty6Xi/nz57N3794Kt1Va4fnggw8oLi4+rDgO53OIjY0t06fK5XJx0kknlTnnH330EQ0bNuTiiy8OzYuOjub666+vdExTpkwhLS2NM844A7CaEi+77DKmTZtWprnsvffeo0uXLuWqG6XrlC6TkpLCLbfccsBlquKmm24qN2//c5mfn8+uXbs45ZRTME2T5cuXA7Bz506+/PJLRowYQbNmzQ4Yz9ChQ/F6vUyfPj007+2338bv9x+yX5tIZSm5Eamixo0b43K5ys3/5ZdfuPDCC0lISCA+Pp769euH/tPOzs4+5Hb//MVQmugcKAE42Lql65eum5mZSWFhYYWjc8I1Ymfjxo0AtG3bttx77dq1C73vdrt57LHH+Pjjj0lLS+O0007j8ccfZ/v27aHlTz/9dC666CLGjx9PSkoKF1xwAa+99lql+rkczufQpEmTcgnB/uet9LhatWpVbrmKjrMigUCAadOmccYZZ7B+/XrWrFnDmjVr6NmzJzt27GDevHmhZdeuXUvHjh0Pur21a9fStm3bsHYsdzgcNGnSpNz8TZs2MXz4cJKTk4mNjaV+/fqcfvrpwL5zWZoIHirudu3a0aNHjzJ9jaZMmcLJJ5+sUWMSNkpuRKpo/79mS2VlZXH66afzww8/8OCDD/K///2PuXPn8thjjwFUaui33W6vcL5pmtW6biTcfvvt/P7770yYMIGoqCjuu+8+2rdvH6oGGIbB9OnTWbRoEaNGjWLLli2MGDGCbt26kZeXd8DtHu7nUBPn7fPPP2fbtm1MmzaN1q1bh6ZLL70U4IAdi4/EgSo4f+5UXcrtdmOz2cote9ZZZ/Hhhx9y9913M2vWLObOnRvqjFyVyxkMHTqUBQsW8Mcff7B27Vq+/fZbVW0krNShWCSM5s+fz+7du5kxYwannXZaaP769esjGNU+qampREVFsWbNmnLvVTSvKpo3bw7AqlWrOPPMM8u8t2rVqtD7pVq2bMmdd97JnXfeyerVqznhhBN46qmnePPNN0PLnHzyyZx88sk8/PDDTJ06lSFDhjBt2jSuvfbaCmOojs+hefPm/Pzzz5imWSZpWLVqVaXWnzJlCqmpqTz//PPl3psxYwYzZ85k0qRJeDweWrZsyc8//3zQ7bVs2ZLvvvuO4uLiA3Y0L636ZWVllZlfWj2rjJ9++onff/+d119/naFDh4bmz507t8xyxx13HMAh4wa4/PLLGT16NG+99RaFhYU4nU4uu+yySsckciiq3IiEUWkFYP+/+H0+Hy+88EKkQirDbrfTv39/Zs2axdatW0Pz16xZw8cffxyWfXTv3p3U1FQmTZpUpvno448/ZuXKlZx33nmAdV2goqKiMuu2bNmSuLi40Hp79+4tVz054YQTAA7aNFUdn8O5557L1q1by/QVKSgo4KWXXjrkuoWFhcyYMYPzzz+fiy++uNw0atQocnNzmT17NmCNIvvhhx8qHDJdekwXXXQRu3bt4rnnnjvgMs2bN8dut/Pll1+Wef9wzkNF59I0TZ555pkyy9WvX5/TTjuNV199lU2bNlUYT6mUlBQGDhzIm2++yZQpUzjnnHNISUmpdEwih6LKjUgYnXLKKSQlJTFs2DBuvfVWDMPgv//971HVLPTAAw/w6aef0rt3b2666SYCgQDPPfccHTt2ZMWKFZXaRnFxMf/85z/LzU9OTubmm2/mscce4+qrr+b000/niiuuCA0FT09P54477gDg999/p1+/flx66aV06NABh8PBzJkz2bFjB5dffjkAr7/+Oi+88AIXXnghLVu2JDc3l//85z/Ex8dz7rnnHjC+6vgcrrvuOp577jmGDh3KsmXLaNiwIf/9738rdeHG2bNnk5uby1/+8pcK3z/55JOpX78+U6ZM4bLLLuOuu+5i+vTpXHLJJaFmuD179jB79mwmTZpEly5dGDp0KG+88QajR49m8eLF9OnTh/z8fD777DNuvvlmLrjgAhISErjkkkv417/+hWEYtGzZkg8++IDMzMxKH3e7du1o2bIlY8aMYcuWLcTHx/Pee+9V2Afs2Wef5dRTT+XEE0/k+uuvp0WLFmzYsIEPP/yw3M/W0KFDQ52zH3rooUrHI1IpERihJVKrHGgo+PHHH1/h8gsXLjRPPvlk0+PxmI0aNTL/9re/mZ988km5IbkHGgpe0dBooMww2QMNBR85cmS5dZs3b24OGzaszLx58+aZXbt2NV0ul9myZUvz5ZdfNu+8804zKirqAGdhn9IhwxVNLVu2DC339ttvm127djXdbreZnJxsDhkyxPzjjz9C7+/atcscOXKk2a5dOzMmJsZMSEgwe/bsWWao9ffff29eccUVZrNmzUy3222mpqaa559/vrl06dJDxlnZz+FAn+WfPx/TNM2NGzeaf/nLX8zo6GgzJSXFvO2228w5c+Yccih4RkaGGRUVZebn5x9wmeHDh5tOp9PctWuXaZqmuXv3bnPUqFFm48aNTZfLZTZp0sQcNmxY6H3TtIZo33vvvWaLFi1Mp9NpNmjQwLz44ovNtWvXhpbZuXOnedFFF5nR0dFmUlKSecMNN5g///xzhUPBDzTE/9dffzX79+9vxsbGmikpKeZ1110XuszA/tswTdP8+eefzQsvvNBMTEw0o6KizLZt25r33XdfuW16vV4zKSnJTEhIKHPJAJFwMEzzKPqTUkQiZtCgQfzyyy+sXr060qHIMcDv99OoUSMyMjJ45ZVXIh2O1DHqcyNyDPrzZfNXr17NRx99RN++fSMTkBxzZs2axc6dO8t0UhYJF1VuRI5BDRs2ZPjw4Rx33HFs3LiRF198Ea/Xy/Lly2ndunWkw5M67LvvvuPHH3/koYceIiUlhe+//z7SIUkdpA7FIsegc845h7feeovt27fjdrvp1asXjzzyiBIbqXYvvvgib775JieccEKZG3eKhJMqNyIiIlKnqM+NiIiI1ClKbkRERKROOeb63ASDQbZu3UpcXNwR3TlXREREao5pmuTm5tKoUaNy90D7s2Muudm6dStNmzaNdBgiIiJSBZs3b67w7vX7O+aSm7i4OMA6OfHx8RGORkRERCojJyeHpk2bhr7HD+aYS25Km6Li4+OV3IiIiNQylelSog7FIiIiUqcouREREZE6RcmNiIiI1CnHXJ8bERGpmwKBAMXFxZEOQ46Ay+U65DDvylByIyIitZppmmzfvp2srKxIhyJHyGaz0aJFC1wu1xFtR8mNiIjUaqWJTWpqKtHR0bpAay1VepHdbdu20axZsyP6HJXciIhIrRUIBEKJTb169SIdjhyh+vXrs3XrVvx+P06ns8rbUYdiERGptUr72ERHR0c4EgmH0uaoQCBwRNtRciMiIrWemqLqhnB9jkpuREREpE5RciMiIlLLpaen8/TTT4dlW/Pnz8cwjFo9+kwdikVERCKgb9++nHDCCWFJSpYsWUJMTMyRB1VHKLkJk0DQJDO3CH/ApGmyOraJiMiRMU2TQCCAw3Hor+r69evXQES1R0SbpSZMmECPHj2Ii4sjNTWVQYMGsWrVqkOu9+6779KuXTuioqLo1KkTH330UQ1Ee3CZuUX0mvA5Zz41P9KhiIjIUW748OEsWLCAZ555BsMwMAyDyZMnYxgGH3/8Md26dcPtdvP111+zdu1aLrjgAtLS0oiNjaVHjx589tlnZbb352YpwzB4+eWXufDCC4mOjqZ169bMnj27yvG+9957HH/88bjdbtLT03nqqafKvP/CCy/QunVroqKiSEtL4+KLLw69N336dDp16oTH46FevXr079+f/Pz8KsdSGRFNbhYsWMDIkSP59ttvmTt3LsXFxZx99tkHPehvvvmGK664gmuuuYbly5czaNAgBg0axM8//1yDkZfnslunsjhgEgyaEY1FRORYZpomBT5/RCbTrNz//8888wy9evXiuuuuY9u2bWzbto2mTZsCcM899/Doo4+ycuVKOnfuTF5eHueeey7z5s1j+fLlnHPOOWRkZLBp06aD7mP8+PFceuml/Pjjj5x77rkMGTKEPXv2HPb5XLZsGZdeeimXX345P/30Ew888AD33XcfkydPBmDp0qXceuutPPjgg6xatYo5c+Zw2mmnAbBt2zauuOIKRowYwcqVK5k/fz6DBw+u9Hmqqog2S82ZM6fM68mTJ5OamsqyZctCJ+bPnnnmGc455xzuuusuAB566CHmzp3Lc889x6RJk6o95gNxOvblicXBIG6bPWKxiIgcywqLA3QY90lE9v3rgwOIdh36qzUhIQGXy0V0dDQNGjQA4LfffgPgwQcf5Kyzzgotm5ycTJcuXUKvH3roIWbOnMns2bMZNWrUAfcxfPhwrrjiCgAeeeQRnn32WRYvXsw555xzWMc0ceJE+vXrx3333QdAmzZt+PXXX3niiScYPnw4mzZtIiYmhvPPP5+4uDiaN29O165dASu58fv9DB48mObNmwPQqVOnw9p/VRxVo6Wys7MB64M8kEWLFtG/f/8y8wYMGMCiRYsqXN7r9ZKTk1Nmqg6llRsAnz9YLfsQEZG6r3v37mVe5+XlMWbMGNq3b09iYiKxsbGsXLnykJWbzp07h57HxMQQHx9PZmbmYcezcuVKevfuXWZe7969Wb16NYFAgLPOOovmzZtz3HHH8de//pUpU6ZQUFAAQJcuXejXrx+dOnXikksu4T//+Q979+497BgO11HToTgYDHL77bfTu3dvOnbseMDltm/fTlpaWpl5aWlpbN++vcLlJ0yYwPjx48Maa0WU3IiIHB08Tju/PjggYvs+Un8e9TRmzBjmzp3Lk08+SatWrfB4PFx88cX4fL6DbufPty8wDINgMPzfT3FxcXz//ffMnz+fTz/9lHHjxvHAAw+wZMkSEhMTmTt3Lt988w2ffvop//rXv7j33nv57rvvaNGiRdhjKXXUVG5GjhzJzz//zLRp08K63bFjx5KdnR2aNm/eHNbtl7LZDBw268qKxQH1uRERiRTDMIh2OSIyHc4Vdl0uV6VuM7Bw4UKGDx/OhRdeSKdOnWjQoAEbNmw4gjN0eNq3b8/ChQvLxdSmTRvsdiuZczgc9O/fn8cff5wff/yRDRs28PnnnwPW59G7d2/Gjx/P8uXLcblczJw5s1pjPioqN6NGjeKDDz7gyy+/pEmTJgddtkGDBuzYsaPMvB07doTaLP/M7XbjdrvDFuvBuBw2/L6AKjciInJI6enpfPfdd2zYsIHY2NgDVlVat27NjBkzyMjIwDAM7rvvvmqpwBzInXfeSY8ePXjooYe47LLLWLRoEc899xwvvPACAB988AHr1q3jtNNOIykpiY8++ohgMEjbtm357rvvmDdvHmeffTapqal899137Ny5k/bt21drzBGt3JimyahRo5g5cyaff/55pUpUvXr1Yt68eWXmzZ07l169elVXmJXmKulU7DvCG36JiEjdN2bMGOx2Ox06dKB+/foH7EMzceJEkpKSOOWUU8jIyGDAgAGceOKJNRbniSeeyDvvvMO0adPo2LEj48aN48EHH2T48OEAJCYmMmPGDM4880zat2/PpEmTeOuttzj++OOJj4/nyy+/5Nxzz6VNmzb84x//4KmnnmLgwIHVGrNhVvd4rIO4+eabmTp1Ku+//z5t27YNzU9ISMDj8QAwdOhQGjduzIQJEwBrKPjpp5/Oo48+ynnnnce0adN45JFH+P777w/aV6dUTk4OCQkJZGdnEx8fH9bj6fHwZ+zM9fLRrX3o0Ci82xYRkfKKiopYv349LVq0ICoqKtLhyBE62Od5ON/fEa3cvPjii2RnZ9O3b18aNmwYmt5+++3QMps2bWLbtm2h16eccgpTp07lpZdeokuXLkyfPp1Zs2ZVKrGpbqWdin0BNUuJiIhESkT73FSmaDR//vxy8y655BIuueSSaojoyLhLm6XU50ZERI5SN954I2+++WaF71111VURvWZcuBwVHYrrCmfoKsVKbkRE5Oj04IMPMmbMmArfC3d3jUhRchNGLlVuRETkKJeamkpqamqkw6hWR811buqC0uTGq+RGREQkYpTchJHTXnoRPyU3IiIikaLkJoxcDutKjWqWEhERiRwlN2GkoeAiIiKRp+QmjFwONUuJiIhEmpKbMApVbtQsJSIi1Sw9PZ2nn366UssahsGsWbOqNZ6jiZKbMNJoKRERkchTchNGuoifiIhI5Cm5CSNdxE9ERCrjpZdeolGjRgSDZb8vLrjgAkaMGMHatWu54IILSEtLIzY2lh49evDZZ5+Fbf8//fQTZ555Jh6Ph3r16nH99deTl5cXen/+/PmcdNJJxMTEkJiYSO/evdm4cSMAP/zwA2eccQZxcXHEx8fTrVs3li5dGrbYwkHJTRgpuREROQqYJvjyIzNV4p6JYN0jcffu3XzxxReheXv27GHOnDkMGTKEvLw8zj33XObNm8fy5cs555xzyMjIYNOmTUd8evLz8xkwYABJSUksWbKEd999l88++4xRo0YB4Pf7GTRoEKeffjo//vgjixYt4vrrr8cwrEEzQ4YMoUmTJixZsoRly5Zxzz334HQ6jziucNLtF8LIpWYpEZHIKy6ARxpFZt9/3wqumEMulpSUxMCBA5k6dSr9+vUDYPr06aSkpHDGGWdgs9no0qVLaPmHHnqImTNnMnv27FASUlVTp06lqKiIN954g5gYK9bnnnuOjIwMHnvsMZxOJ9nZ2Zx//vm0bNkSgPbt24fW37RpE3fddRft2rUDoHXr1kcUT3VQ5SaMdJ0bERGprCFDhvDee+/h9XoBmDJlCpdffjk2m428vDzGjBlD+/btSUxMJDY2lpUrV4alcrNy5Uq6dOkSSmwAevfuTTAYZNWqVSQnJzN8+HAGDBhARkYGzzzzDNu2bQstO3r0aK699lr69+/Po48+ytq1a484pnBT5SaMNFpKROQo4Iy2KiiR2nclZWRkYJomH374IT169OCrr77i//7v/wAYM2YMc+fO5cknn6RVq1Z4PB4uvvhifD5fdUVexmuvvcatt97KnDlzePvtt/nHP/7B3LlzOfnkk3nggQe48sor+fDDD/n444+5//77mTZtGhdeeGGNxFYZSm7CaN9oqcq1uYqISDUwjEo1DUVaVFQUgwcPZsqUKaxZs4a2bdty4oknArBw4UKGDx8eShjy8vLYsGFDWPbbvn17Jk+eTH5+fqh6s3DhQmw2G23btg0t17VrV7p27crYsWPp1asXU6dO5eSTTwagTZs2tGnThjvuuIMrrriC11577ahKbtQsFUb7OhQHIhyJiIjUBkOGDOHDDz/k1VdfZciQIaH5rVu3ZsaMGaxYsYIffviBK6+8stzIqiPZZ1RUFMOGDePnn3/miy++4JZbbuGvf/0raWlprF+/nrFjx7Jo0SI2btzIp59+yurVq2nfvj2FhYWMGjWK+fPns3HjRhYuXMiSJUvK9Mk5GqhyE0YaLSUiIofjzDPPJDk5mVWrVnHllVeG5k+cOJERI0ZwyimnkJKSwt13301OTk5Y9hkdHc0nn3zCbbfdRo8ePYiOjuaiiy5i4sSJofd/++03Xn/9dXbv3k3Dhg0ZOXIkN9xwA36/n927dzN06FB27NhBSkoKgwcPZvz48WGJLVwM06zkuLU6Iicnh4SEBLKzs4mPjw/rtmct38Ltb6/g1FYpvHltz7BuW0REyisqKmL9+vW0aNGCqKioSIcjR+hgn+fhfH+rWSqMVLkRERGJPCU3YVQ6FNyroeAiIlJDpkyZQmxsbIXT8ccfH+nwIkJ9bsLIWVK5KVblRkREashf/vIXevasuCvE0Xbl4Jqi5CaMdBE/ERGpaXFxccTFxUU6jKOKmqXCSH1uREREIk/JTRjp3lIiIiKRp+QmjFS5ERERiTwlN2Gk5EZERCTylNyEkdNuAOpQLCIiEklKbsIoVLkJBDnGLvwsIiIRlJ6eztNPPx3pMI4aGgoeRm67HQDThEDQxFFSyREREfmzvn37csIJJ4QlKVmyZEnoDt+i5CasnI59yYwvEMRhV2FMRESqxjRNAoEADsehv6rr169fAxHVHhH99v3yyy/JyMigUaNGGIbBrFmzDrnOlClT6NKlC9HR0TRs2JARI0awe/fu6g+2Elz7JTPqVCwiIgcyfPhwFixYwDPPPINhGBiGweTJkzEMg48//phu3brhdrv5+uuvWbt2LRdccAFpaWnExsbSo0cPPvvsszLb+3OzlGEYvPzyy1x44YVER0fTunVrZs+eXanYAoEA11xzDS1atMDj8dC2bVueeeaZcsu9+uqrHH/88bjdbho2bMioUaNC72VlZXHDDTeQlpZGVFQUHTt25IMPPqjayaqCiFZu8vPz6dKlCyNGjGDw4MGHXH7hwoUMHTqU//u//yMjI4MtW7Zw4403ct111zFjxowaiPjg7DYDw7CapdSpWEQkMkzTpNBfGJF9exweDOPQXRKeeeYZfv/9dzp27MiDDz4IwC+//ALAPffcw5NPPslxxx1HUlISmzdv5txzz+Xhhx/G7XbzxhtvkJGRwapVq2jWrNkB9zF+/Hgef/xxnnjiCf71r38xZMgQNm7cSHJy8kFjCwaDNGnShHfffZd69erxzTffcP3119OwYUMuvfRSAF588UVGjx7No48+ysCBA8nOzmbhwoWh9QcOHEhubi5vvvkmLVu25Ndff8Ve0nWjJkQ0uRk4cCADBw6s9PKLFi0iPT2dW2+9FYAWLVpwww038Nhjj1VXiIfFMAxcdhtef1CVGxGRCCn0F9JzasX3Wqpu3135HdHO6EMul5CQgMvlIjo6mgYNGgDw22+/AfDggw9y1llnhZZNTk6mS5cuodcPPfQQM2fOZPbs2WWqJX82fPhwrrjiCgAeeeQRnn32WRYvXsw555xz0NicTifjx48PvW7RogWLFi3inXfeCSU3//znP7nzzju57bbbQsv16NEDgM8++4zFixezcuVK2rRpA8Bxxx13yHMSTrWqU0ivXr3YvHkzH330EaZpsmPHDqZPn8655557wHW8Xi85OTllpuqka92IiMiR6N69e5nXeXl5jBkzhvbt25OYmEhsbCwrV65k06ZNB91O586dQ89jYmKIj48nMzOzUjE8//zzdOvWjfr16xMbG8tLL70U2l9mZiZbt26lX79+Fa67YsUKmjRpEkpsIqFWdSju3bs3U6ZM4bLLLqOoqAi/309GRgbPP//8AdeZMGFCmQy0uu27BYOGgouIRILH4eG7K7+L2L6P1J9HPY0ZM4a5c+fy5JNP0qpVKzweDxdffDE+n++g2/nzHcENwyAYPPQf3tOmTWPMmDE89dRT9OrVi7i4OJ544gm++846px7PwY/xUO/XhFqV3Pz666/cdtttjBs3jgEDBrBt2zbuuusubrzxRl555ZUK1xk7diyjR48Ovc7JyaFp06bVFqMqNyIikWUYRqWahiLN5XIRCAQOudzChQsZPnw4F154IWBVcjZs2FBtcS1cuJBTTjmFm2++OTRv7dq1oedxcXGkp6czb948zjjjjHLrd+7cmT/++IPff/89YtWbWpXcTJgwgd69e3PXXXcB1gmMiYmhT58+/POf/6Rhw4bl1nG73bjd7hqLcd+F/A79AysiIseu9PR0vvvuOzZs2EBsbOwBqyqtW7dmxowZZGRkYBgG9913X6UqMFXVunVr3njjDT755BNatGjBf//7X5YsWUKLFi1CyzzwwAPceOONpKamhjoPL1y4kFtuuYXTTz+d0047jYsuuoiJEyfSqlUrfvvtNwzDOGR/n3CpVX1uCgoKsNnKhmwPXTjv6GgGctpLKzdHRzwiInJ0GjNmDHa7nQ4dOlC/fv0D9qGZOHEiSUlJnHLKKWRkZDBgwABOPPHEaovrhhtuYPDgwVx22WX07NmT3bt3l6niAAwbNoynn36aF154geOPP57zzz+f1atXh95/77336NGjB1dccQUdOnTgb3/7W6WqVOFimBHMCvLy8lizZg0AXbt2ZeLEiZxxxhkkJyfTrFkzxo4dy5YtW3jjjTcAmDx5Mtdddx3PPvtsqFnq9ttvx2azhdoCDyUnJ4eEhASys7OJj48P+zGd+8xX/Loth9dHnMTpbXRRJRGR6lRUVMT69etp0aIFUVFRkQ5HjtDBPs/D+f6OaLPU0qVLy7TXlfaNGTZsGJMnT2bbtm1lMtnhw4eTm5vLc889x5133kliYiJnnnnmUTMUHNTnRkREJNIimtz07dv3oM1JkydPLjfvlltu4ZZbbqnGqI7MvtFSSm5EROToc+ONN/Lmm29W+N5VV13FpEmTajii8KtVHYprA1VuRETkaPbggw8yZsyYCt+rju4akaDkJsyU3IiIyNEsNTWV1NTUSIdRrWrVaKnawGm37imie0uJiIhEhpKbMHM5rKHpqtyIiIhEhpKbMCvtUKzKjYiISGQouQkzl8NqlipW5UZERCQilNyEmSo3IiIikaXkJsw0WkpERGpCeno6Tz/9dKTDOCopuQkzpyo3IiIiEaXkJsxUuREREYksJTdhpuRGREQO5aWXXqJRo0YEg2W/Ky644AJGjBjB2rVrueCCC0hLSyM2NpYePXrw2WefVXl/EydOpFOnTsTExNC0aVNuvvlm8vLyyiyzcOFC+vbtS3R0NElJSQwYMIC9e/cCEAwGefzxx2nVqhVut5tmzZrx8MMPVzme6qbkJsx0bykRkcgyTZNgQUFEpoPdL3F/l1xyCbt37+aLL74IzduzZw9z5sxhyJAh5OXlce655zJv3jyWL1/OOeecQ0ZGRpmbSR8Om83Gs88+yy+//MLrr7/O559/zt/+9rfQ+ytWrKBfv3506NCBRYsW8fXXX5ORkUEgEABg7NixPProo9x33338+uuvTJ06lbS0tCrFUhN0+4UwC1VulNyIiESEWVjIqhO7RWTfbb9fhhEdfcjlkpKSGDhwIFOnTqVfv34ATJ8+nZSUFM444wxsNhtdunQJLf/QQw8xc+ZMZs+ezahRow47rttvvz30PD09nX/+85/ceOONvPDCCwA8/vjjdO/ePfQa4PjjjwcgNzeXZ555hueee45hw4YB0LJlS0499dTDjqOmqHITZqGh4GqWEhGRgxgyZAjvvfceXq8XgClTpnD55Zdjs9nIy8tjzJgxtG/fnsTERGJjY1m5cmWVKzefffYZ/fr1o3HjxsTFxfHXv/6V3bt3U1BQAOyr3FRk5cqVeL3eA75/NFLlJsz2jZaqXGlSRETCy/B4aPv9sojtu7IyMjIwTZMPP/yQHj168NVXX/F///d/AIwZM4a5c+fy5JNP0qpVKzweDxdffDE+n++wY9qwYQPnn38+N910Ew8//DDJycl8/fXXXHPNNfh8PqKjo/EcJO6DvXe0UnITZvs6FAciHImIyLHJMIxKNQ1FWlRUFIMHD2bKlCmsWbOGtm3bcuKJJwJW597hw4dz4YUXApCXl8eGDRuqtJ9ly5YRDAZ56qmnsNms76h33nmnzDKdO3dm3rx5jB8/vtz6rVu3xuPxMG/ePK699toqxVDTlNyEmUZLiYhIZQ0ZMoTzzz+fX375hauuuio0v3Xr1syYMYOMjAwMw+C+++4rN7Kqslq1akVxcTH/+te/yMjIYOHChUyaNKnMMmPHjqVTp07cfPPN3HjjjbhcLr744gsuueQSUlJSuPvuu/nb3/6Gy+Wid+/e7Ny5k19++YVrrrnmiI6/uqjPTZjtGy2lZikRETm4M888k+TkZFatWsWVV14Zmj9x4kSSkpI45ZRTyMjIYMCAAaGqzuHq0qULEydO5LHHHqNjx45MmTKFCRMmlFmmTZs2fPrpp/zwww+cdNJJ9OrVi/fffx+Hw6qB3Hfffdx5552MGzeO9u3bc9lll5GZmVn1A69mhlnZcWt1RE5ODgkJCWRnZxMfHx/27S9cs4shL39H27Q4PrnjtLBvX0RE9ikqKmL9+vW0aNGCqKioSIcjR+hgn+fhfH+rchNmGgouIiISWUpuwsypoeAiIlKDpkyZQmxsbIVT6bVqjjXqUBxmLt04U0REatBf/vIXevbsWeF7TqezhqM5Oii5CTONlhIRkZoUFxdHXFxcpMM4qqhZKsx0bykREZHIUnITZqrciIjUvGNs4G+dFa7PUclNmJUmN/6gSTCoXzYRkepU2qek9B5JUruV3l7Cbrcf0XbU5ybMnHYj9NwXCBJlO7IPSEREDsxut5OYmBi6oFx0dDSGYRxiLTkaBYNBdu7cSXR0dOjigVWl5CbMSis3UJLcOJXciIhUpwYNGgAc1VfMlcqx2Ww0a9bsiBNUJTdhVtqhGKBY/W5ERKqdYRg0bNiQ1NRUiouLIx2OHAGXyxW6ueeRUHITZoZh4LQbFAdMXetGRKQG2e32I+6rIXWDOhRXA5euUiwiIhIxEU1uvvzySzIyMmjUqBGGYTBr1qxDruP1ern33ntp3rw5breb9PR0Xn311eoP9jCU9rvRtW5ERERqXkSbpfLz8+nSpQsjRoxg8ODBlVrn0ksvZceOHbzyyiu0atWKbdu2EQweXUlE6f2lvKrciIiI1LiIJjcDBw5k4MCBlV5+zpw5LFiwgHXr1pGcnAxAenp6NUVXdbqQn4iISOTUqj43s2fPpnv37jz++OM0btyYNm3aMGbMGAoLCyMdWhn7mqV0ET8REZGaVqtGS61bt46vv/6aqKgoZs6cya5du7j55pvZvXs3r732WoXreL1evF5v6HVOTk61x6kOxSIiIpFTqyo3wWAQwzCYMmUKJ510Eueeey4TJ07k9ddfP2D1ZsKECSQkJISmpk2bVnucoWapQKDa9yUiIiJl1arkpmHDhjRu3JiEhITQvPbt22OaJn/88UeF64wdO5bs7OzQtHnz5mqP0xmq3KhZSkREpKbVquSmd+/ebN26lby8vNC833//HZvNRpMmTSpcx+12Ex8fX2aqbqFmKQ0FFxERqXERTW7y8vJYsWIFK1asAGD9+vWsWLGCTZs2AVbVZejQoaHlr7zySurVq8fVV1/Nr7/+ypdffsldd93FiBEj8Hg8kTiECmm0lIiISORENLlZunQpXbt2pWvXrgCMHj2arl27Mm7cOAC2bdsWSnQAYmNjmTt3LllZWXTv3p0hQ4aQkZHBs88+G5H4D6S0WUoX8RMREal5ER0t1bdvX0zzwP1SJk+eXG5eu3btmDt3bjVGdeTcqtyIiIhETK3qc1NbqFlKREQkcpTcVAOn3QDUoVhERCQSlNxUA1VuREREIkfJTTVw2e2AKjciIiKRoOSmGjgdVrNUsSo3IiIiNU7JTTVw6yJ+IiIiEaPkphqoz42IiEjkKLmpBk5VbkRERCJGyU01UOVGREQkcpTcVAMlNyIiIpGj5KYa6N5SIiIikaPkphqE7i2l5EZERKTGKbmpBi67mqVEREQiRclNNdg3WurAdzwXERGR6qHkphqoQ7GIiEjkKLmpBvuSm0CEIxERETn2KLmpBvtGS6lZSkREpKYpuakGbjVLiYiIRIySm2rg0lBwERGRiFFyUw1CzVKq3IiIiNQ4JTfVoLRy41XlRkREpMYpuakG+1/EzzTVqVhERKQmKbmpBqXJDYA/qORGRESkJim5qQalzVKgEVMiIiI1TclNNVByIyIiEjlKbqqB3WZgM6znxepULCIiUqOU3FST0IgpVW5ERERqlJKbahIaMaXKjYiISI2qUnJz+umn88Ybb1BYWBjueOqM0sqNmqVERERqVpWSm65duzJmzBgaNGjAddddx7fffhvuuGq9/a91IyIiIjWnSsnN008/zdatW3nttdfIzMzktNNOo0OHDjz55JPs2LEj3DHWSqrciIiIREaV+9w4HA4GDx7M+++/zx9//MGVV17JfffdR9OmTRk0aBCff/55OOOsdUrvL6UOxSIiIjXriDsUL168mPvvv5+nnnqK1NRUxo4dS0pKCueffz5jxow56LpffvklGRkZNGrUCMMwmDVrVqX3u3DhQhwOByeccMKRHUA1Cd0ZXMmNiIhIjapScpOZmclTTz1Fx44d6dOnDzt37uStt95iw4YNjB8/npdffplPP/2USZMmHXQ7+fn5dOnSheeff/6w9p+VlcXQoUPp169fVcKvEfuapXT7BRERkZrkqMpKTZo0oWXLlowYMYLhw4dTv379cst07tyZHj16HHQ7AwcOZODAgYe9/xtvvJErr7wSu91+WNWemuRUh2IREZGIqFJyM2/ePPr06XPQZeLj4/niiy+qFNTBvPbaa6xbt44333yTf/7zn4dc3uv14vV6Q69zcnLCHlNF3KXNUoFAjexPRERELFVqlmrSpAmrV68uN3/16tVs2LDhSGM6oNWrV3PPPffw5ptv4nBULi+bMGECCQkJoalp06bVFt/+SoeCF/vVLCUiIlKTqpTcDB8+nG+++abc/O+++47hw4cfaUwVCgQCXHnllYwfP542bdpUer2xY8eSnZ0dmjZv3lwt8f1ZaLSUhoKLiIjUqCo1Sy1fvpzevXuXm3/yySczatSoIw6qIrm5uSxdupTly5eH9hEMBjFNE4fDwaeffsqZZ55Zbj23243b7a6WmA5Go6VEREQio0rJjWEY5ObmlpufnZ1NoJr6mMTHx/PTTz+VmffCCy/w+eefM336dFq0aFEt+60qXcRPREQkMqqU3Jx22mlMmDCBt956C7vdDljNRhMmTODUU0+t9Hby8vJYs2ZN6PX69etZsWIFycnJNGvWjLFjx7JlyxbeeOMNbDYbHTt2LLN+amoqUVFR5eYfDTRaSkREJDKqlNw89thjnHbaabRt2zY0auqrr74iJyfnsK5MvHTpUs4444zQ69GjRwMwbNgwJk+ezLZt29i0aVNVQow4t5qlREREIsIwTbNKw3m2bt3Kc889xw8//IDH46Fz586MGjWK5OTkcMcYVjk5OSQkJJCdnU18fHy17efhD3/lP1+t54bTjmPsue2rbT8iIiLHgsP5/q5S5QagUaNGPPLII1Vdvc4r7XOje0uJiIjUrConNwAFBQVs2rQJn89XZn7nzp2PKKi6wFXSF8mnDsUiIiI1qkrJzc6dO7n66qv5+OOPK3y/ukZM1SZOhwFAsSo3IiIiNapKF/G7/fbbycrK4rvvvsPj8TBnzhxef/11WrduzezZs8MdY61UeoViVW5ERERqVpUqN59//jnvv/8+3bt3x2az0bx5c8466yzi4+OZMGEC5513XrjjrHU0WkpERCQyqlS5yc/PJzU1FYCkpCR27twJQKdOnfj+++/DF10tVnqdG13ET0REpGZVKblp27Ytq1atAqBLly78+9//ZsuWLUyaNImGDRuGNcDaSqOlREREIqNKzVK33XYb27ZtA+D+++/nnHPOYcqUKbhcLiZPnhzO+Got3VtKREQkMqqU3Fx11VWh5926dWPjxo389ttvNGvWjJSUlLAFV5upWUpERCQyDrtZqri4mJYtW7Jy5crQvOjoaE488UQlNvsJVW6U3IiIiNSow05unE4nRUVF1RFLneLWjTNFREQiokodikeOHMljjz2G3+8Pdzx1htNR2ixVpVt3iYiISBVVqc/NkiVLmDdvHp9++imdOnUiJiamzPszZswIS3C1mUuVGxERkYioUnKTmJjIRRddFO5Y6hQNBRcREYmMKiU3r732WrjjqHM0WkpERCQyqtTnRg5Nt18QERGJjCpVblq0aIFhGAd8f926dVUOqK7QUHAREZHIqFJyc/vtt5d5XVxczPLly5kzZw533XVXOOKq9UqbpQJBk0DQxG47cDIoIiIi4VPl2y9U5Pnnn2fp0qVHFFBdUVq5Aavfjd1mj2A0IiIix46w9rkZOHAg7733Xjg3WWuVDgUHjZgSERGpSWFNbqZPn05ycnI4N1lrOe37mqE0YkpERKTmVKlZqmvXrmU6FJumyfbt29m5cycvvPBC2IKrzQzDwGW34QsENWJKRESkBlUpuRk0aFCZ1zabjfr169O3b1/atWsXjrjqBJdDyY2IiEhNq1Jyc//994c7jjqptGlKzVIiIiI1p0p9bj766CM++eSTcvM/+eQTPv744yMOqq7QLRhERERqXpWSm3vuuYdAIFBuvmma3HPPPUccVF2hC/mJiIjUvColN6tXr6ZDhw7l5rdr1441a9YccVB1Rej+UqrciIiI1JgqJTcJCQkV3mJhzZo1xMTEHHFQdUXptW5UuREREak5VUpuLrjgAm6//XbWrl0bmrdmzRruvPNO/vKXv4QtuNqu9OaZ6lAsIiJSc6qU3Dz++OPExMTQrl07WrRoQYsWLWjfvj316tXjySefDHeMtVZps5SGgouIiNScKg0FT0hI4JtvvmHu3Ln88MMPeDweOnfuzGmnnRbu+Go1jZYSERGpeVW+/YJhGJx99tncddddjBo1qkqJzZdffklGRgaNGjXCMAxmzZp10OVnzJjBWWedRf369YmPj6dXr14VDkk/WrhCzVJmhCMRERE5dlQpubn11lt59tlny81/7rnnuP322yu9nfz8fLp06cLzzz9fqeW//PJLzjrrLD766COWLVvGGWecQUZGBsuXL6/0PmuSmqVERERqXpWapd577z1mz55dbv4pp5zCo48+ytNPP12p7QwcOJCBAwdWer9/3u4jjzzC+++/z//+9z+6du1a6e3UlNB1bvzlrwkkIiIi1aNKyc3u3btJSEgoNz8+Pp5du3YdcVCVFQwGyc3NPeidyL1eL16vN/Q6JyenJkIDwG1Xs5SIiEhNq1KzVKtWrZgzZ065+R9//DHHHXfcEQdVWU8++SR5eXlceumlB1xmwoQJJCQkhKamTZvWWHxOXedGRESkxlWpcjN69GhGjRrFzp07OfPMMwGYN28eTz31VKWbpI7U1KlTGT9+PO+//z6pqakHXG7s2LGMHj069DonJ6fGEhyNlhIREal5VUpuRowYgdfr5eGHH+ahhx4CID09nRdffJGhQ4eGNcCKTJs2jWuvvZZ3332X/v37H3RZt9uN2+2u9pgq4tJF/ERERGpclZIbgJtuuombbrqJnTt34vF4iI2NBWDPnj0H7QNzpN566y1GjBjBtGnTOO+886ptP+Gg0VIiIiI1r8rXuSlVv359YmNj+fTTT7n00ktp3LhxpdfNy8tjxYoVrFixAoD169ezYsUKNm3aBFhNSvtXgqZOncrQoUN56qmn6NmzJ9u3b2f79u1kZ2cf6WFUi32jpZTciIiI1JQjSm42btzI/fffT3p6Opdccgk2m4033nij0usvXbqUrl27hoZxjx49mq5duzJu3DgAtm3bFkp0AF566SX8fj8jR46kYcOGoem22247ksOoNrq3lIiISM077GYpn8/HjBkzePnll1m4cCH9+/fnjz/+YPny5XTq1OmwttW3b19M88DDpCdPnlzm9fz58w833Ihy2g1AlRsREZGadFiVm1tuuYVGjRrxzDPPcOGFF/LHH3/wv//9D8MwsNvt1RVjreUq6XPjVeVGRESkxhxW5ebFF1/k7rvv5p577iEuLq66YqozXA4r4StW5UZERKTGHFbl5r///S+LFy+mYcOGXHbZZXzwwQcEArq1wIGEmqVUuREREakxh5XcXHHFFcydO5effvqJdu3aMXLkSBo0aEAwGOTXX3+trhhrLY2WEhERqXlVGi3VokULxo8fz4YNG3jzzTe56KKLuOqqq2jSpAm33npruGOstVx2jZYSERGpaVW+iB+AYRgMGDCAAQMGsGfPHt544w1ee+21cMVW66lyIyIiUvMOq3LTp08fnnzySX7//fdy7yUnJ3P77bfzww8/hC242k73lhIREal5h5XcXHfddSxatIhu3brRvn177r77bhYuXHjQa9Ucy5xqlhIREalxh5XcDB06lPfee49du3bx1FNPkZWVxSWXXEKDBg0YMWIEs2bNorCwsLpirXVCzVJKbkRERGpMlToUu91uzj33XP7973+zdetWZs+eTcOGDbnvvvuoV68e559/PgsXLgx3rLWOSzfOFBERqXFHfONMgJ49e/Lwww/z008/8dNPP9GvXz+2bdsWjk3Xaq7QvaXUbCciIlJTqjRaavPmzRiGQZMmTQBYvHgxU6dOpUOHDlx//fXccccdYQ2ytlLlRkREpOZVqXJz5ZVX8sUXXwCwfft2+vfvz+LFi7n33nt58MEHwxpgbaah4CIiIjWvSsnNzz//zEknnQTAO++8Q6dOnfjmm2+YMmVKuTt5H8tKR0v5AkGNKBMREakhVUpuiouLcbvdAHz22Wf85S9/AaBdu3bqa7Of0soNqN+NiIhITalScnP88cczadIkvvrqK+bOncs555wDwNatW6lXr15YA6zN3PslNxoOLiIiUjOqlNw89thj/Pvf/6Zv375cccUVdOnSBYDZs2eHmqtkX7MUQLH63YiIiNSIKo2W6tu3L7t27SInJ4ekpKTQ/Ouvv57o6OiwBVfb2W0GdptBIGiqciMiIlJDqlS5KSwsxOv1hhKbjRs38vTTT7Nq1SpSU1PDGmBtp+HgIiIiNatKyc0FF1zAG2+8AUBWVhY9e/bkqaeeYtCgQbz44othDbC2c9oNQH1uREREakqVkpvvv/+ePn36ADB9+nTS0tLYuHEjb7zxBs8++2xYA6ztXA47oMqNiIhITalSclNQUEBcXBwAn376KYMHD8Zms3HyySezcePGsAZY27l1IT8REZEaVaXkplWrVsyaNYvNmzfzySefcPbZZwOQmZlJfHx8WAOs7UqbpYrVLCUiIlIjqpTcjBs3jjFjxpCens5JJ51Er169AKuK07Vr17AGWNvpFgwiIiI1q0pDwS+++GJOPfVUtm3bFrrGDUC/fv248MILwxZcXVCa3HhVuREREakRVUpuABo0aECDBg34448/AGjSpIku4FeB0gv56SJ+IiIiNaNKzVLBYJAHH3yQhIQEmjdvTvPmzUlMTOShhx4iGNSX+P5c+908U0RERKpflSo39957L6+88gqPPvoovXv3BuDrr7/mgQceoKioiIcffjisQdZm6nMjIiJSs6qU3Lz++uu8/PLLobuBA3Tu3JnGjRtz8803K7nZT2nlRqOlREREakaVmqX27NlDu3btys1v164de/bsOeKg6hJVbkRERGpWlZKbLl268Nxzz5Wb/9xzz9G5c+cjDqouCSU3ATPCkYiIiBwbqpTcPP7447z66qt06NCBa665hmuuuYYOHTowefJknnzyyUpv58svvyQjI4NGjRphGAazZs065Drz58/nxBNPxO1206pVKyZPnlyVQ6gxTt04U0REpEZVKbk5/fTT+f3337nwwgvJysoiKyuLwYMH88svv/Df//630tvJz8+nS5cuPP/885Vafv369Zx33nmcccYZrFixgttvv51rr72WTz75pCqHUSPULCUiIlKzDNM0w9Ze8sMPP3DiiScSCAQOPxDDYObMmQwaNOiAy9x99918+OGH/Pzzz6F5l19+OVlZWcyZM6dS+8nJySEhIYHs7OwauVXEA7N/YfI3Gxh1RivGDGhb7fsTERGpiw7n+7tKlZtIWbRoEf379y8zb8CAASxatChCER3avj43qtyIiIjUhCpfoTgStm/fTlpaWpl5aWlp5OTkUFhYiMfjKbeO1+vF6/WGXufk5FR7nPtzqc+NiIhIjapVlZuqmDBhAgkJCaGpadOmNbp/VW5ERERq1mFVbgYPHnzQ97Oyso4klkNq0KABO3bsKDNvx44dxMfHV1i1ARg7diyjR48Ovc7JyanRBEejpURERGrWYSU3CQkJh3x/6NChRxTQwfTq1YuPPvqozLy5c+fSq1evA67jdrtxu93VFtOhaLSUiIhIzTqs5Oa1114L687z8vJYs2ZN6PX69etZsWIFycnJNGvWjLFjx7JlyxbeeOMNAG688Uaee+45/va3vzFixAg+//xz3nnnHT788MOwxhVOpcmNbr8gIiJSMyLa52bp0qV07dqVrl27AjB69Gi6du3KuHHjANi2bRubNm0KLd+iRQs+/PBD5s6dS5cuXXjqqad4+eWXGTBgQETirwyX3QBUuREREakpER0t1bdvXw52mZ2Krj7ct29fli9fXo1RhZc6FIuIiNSsOj9aKtJcdjugyo2IiEhNUXJTzZylzVKq3IiIiNQIJTfVTKOlREREapaSm2qm0VIiIiI1S8lNNdPtF0RERGpWrbq3VG2kZik5GNM08QV9FBYXUuAvoNBfSKG/kGBxMa5iE7fPxOkN4PD6cRT5cZgGRkoywdR6mB4X/qCfQDCAP+inOFhcZvIFfBQHizEwiHJEWZN936PT7sQXKLvvokARRf4iTNPEbrNjM2zYDTt2v4mt0Esw4CfX7iPH8JJbnEducS55vjzyi/Nx2px4ig3is4uJzfISk+Ulem8hjiDYnC5sDid2p6tkcmPabRQZxRRSTCE+8k0f+WYR+YYPX7QDb7SL4hgXxVEODMP6PTIMA5thw2bYMDCwG3YMw+rX5vd5MQuLCHoLodCLWVSE4SvGgQ2n4cRhc+K0OXCWPAYN8BkBayKA1/DjxY/PCELQxDQDmGYQM2gCJmYwSNCAgA0CBgRsJkE7BICAwyDgtGHsFxsG2LBeO2wOHEGI8oHHa+L2mhAMEjRLJoIEggFM08SGQZThxGO4cBsu3DhxGw6chgO/zcRnM/HZgvhsQYptQby2IP5AMYGSn4VgwE8g4LceDZOA20HQaSfgchBwObDbHaFzBkDQxB4wsQWC2AMmTtNOlOHEjYMonLgNJy4c2LHhw4+PgPVYct58+CmyBym0B/CaZX8GAevYDUfJox2XaccVMHCaNlxBG46ggcu0Hu2mgc9lozDKoNAJAcM6L37Tb23LcGAzbDgDBtFFQTyFQdzFJu5gyXaDBi7TjjNg4MSGzeYAux2jdHJYr334yfMXkBssINefR66/gJxgHkUBL7GmmzjDQxxuYo0oYnDjwYnPDnmOYnLsxeTai8m2FZFlKyJotxHtiiHGGUucM5YYZwyxrjiinftfNd8IPZimibe4kMKifHzefIp8Bfi8Bfi8hRQFi8gziimw+cjFSz5evAEfvqAPl82F0+7EbXfjtrtx2qznHoeHGGcM0c5ooh3RoecOmwNvwIsv4KPIX4Qv4Au9LjaL8Qf95SabYcNpcxAVdBDtt+MJ2PD4rc/JOocODLsNm8MJdjvYbHgDXooCRRT6i6z/Q/yFFPmLiI9K4N+XTqvm/0EPTMlNNds3FPzAQ96PdWYgQCAnB//evRTv3YN/zx782VkEcnMI5uUTzMsjkJ+HmZdPMC8fw+nEnpiIIzERZ2ISjoRE7IkJYLdTtDuTgszteHftoHjPbgK792BmWzdLNe02TJuBabeBzWa9djoIelwEo9wEo5zWo8dFwGnDH/AT8Pso9vvwB4qtLxB/MQG/D7/fS6DYeh0smShJCOyGHYdhPdoNO3bTwFHos5KTomJc3gAubxC3N4gtaGILgs2kzKPTBBMoKpkqkhcFu+Jhd7zB7jjrS9cRBEfAmuwlz13FEFVsEuUDd7H1BRtVDE4/+O3gc0Cxw3r0OaDYDs4AeHzg9JU8BvbtNw5oAPicUOSEIpe178R8iPEeINgDiK3EMgED8qOs4w3aSo7vT8fp9FvzIs1nt85Lsd06pwGbdf48XnD7Ix2dpdhuTaU/H/Yw/tfkt4HXWfKz5ATDtD4bZ6Dk0V/55oIgUOSGAjcUuKzfjZgi62fMdZScy5rgc1i/p4bpw9j//4mSqVQQrOQJMEtyqaANgsZ+jyXPMUPpFoa579FZ8v9FOJp0suJscGkYNlRFSm6q2b57SwUOseTRw5+dTe7mdXhz9hIoKCRQVEigqIBgURHBoiJ8+bkUZe/Bl5OFPy+HQF4e5BVgK/Ri8wexBYLYSv8S9FuPACYmQSBomCXPrb8YYwqrp33UXjLVZgHDSh6KXFYiYRqQnAfRXogtsqb0zKp/OzmCVqJzuGxY60UVAwVl3yv2OClMiiY/MYq8RBfFDjD9AfD7wR+AgDXZA2bJX9s2XKb117gjaODwB7Hne3HkFWIrDmA3Ib7QmirDtBkE3U5MtwvT5bQSWkwwTcySv5yt12APBDFKfl6NkudGIIhpM8AwoKQCg63kJzRoYgQCEAhiBMtnU66ANR1M0OUk6HFh2m3sq58YoX9Nw7COwWYdS6DkC8mkJBEu/R0reTSKA1asBiWPBhg2qzoTDGL4ijGK92UDzkDZZLXCGB126xzYDIKlfxQAtqCJEQxiBE2MwL7npRxBcHgPL8k17SV/aJTs01bks44N6+c8+iDbCkS7CUS5CDptBOw2gnaDgMNG0GYllphmSaxB61yU/L9kM8FuWpWifX9UmBgmBJ12gg4bQbsNv8OwJpuJo9jE6bOqqPaiYmxFvjLHfiRKj98ImmU+K7ASucokczawMpv9H48w4Q867Nbvkt1m/byXnENKfwbK/A4YZdZNdCce2c6PkJKbahbqcxPGDsXBwkICe/fi37OXwN69BLJKH7PAZsdwubC5XRQ7bBTa/OTbfBQGfRT7CvH5ivAVF1LsK6LY78Wfn48tczfOzCxiduUTv9dLdNHBf2FtQHTJFE4FbsjxQJ4Hcj2G9RebGwrdUOiyXhe5rL84YwshtsgseYTYQhNHAHKjDXJiDIri3PjiPQQSYjDjYzFsduxBMEwTe9D668ceLPkPyxuwmn58AZxev/Xcb2Kz2bHbHdhsVinfZrceHQ4XdocLh9OF0xmFw+nG6XCD3UbADBAI+ik2AwRMP34zQAATe0ws9pgYHHHxOGPjcMbG445NwB0VQ5QzmihXNA6nC8Nms8roLhe2mBgMpxPDMAiaQavUHyjGbrNj5BfC9l34d2yneOs2/Jk7MINBa3mnq+SxZHK5sMVEY/NEW4/R0eCJwnQ6sPmD4PMR9HoxS6ag12tVx2JisO0/RUeD3Y5ZVESwoIBgYSHBgkLMwgKCPh+OlBQcqWnYY2PC9jMRLCoikJ1DIDuLYHY2ZtDc77icZY7T5vFgeDyhc1bdTNP6T970+zGL/Zg+qyks6PVi+nyYRUWYgUDJ+YvFHhsT+kxrmhkIhD5bs6gI0+ezmmgcfzqPDgeG/fD+JDCDQWvbRUXW8RcVWa8LCzFsNgy3G8PlwnC5MVxObG53aH84HOU+K9M0rfXz8gjk5pZUb3PBbsceH489Lg5bXJx1Lg8z1nAqjdP0HyLzKL1Q7f6PdgeGY18z2f7nwDRNzOLi0O+j6fViFhdbCbbNjmEzrCYhw7D+vyjZpmma+5IaSn42A0EIBjADAWu/gQBmMEgoacdq6i1Nig2XC1tUFIbHYz06am+KUHsjryX2jZY6sgy/eNs2cj6eQ85HH1H088+Hta4NONyvmxyP1QzgcxoUO6HYaaPYacPvNPC7HZgxHoiJxh4bizMuAVd8Iu7YBHA5Me12gk4bps1G0GHDdNhw2l147FFE2dx47FF47FG47S7crhjsSYk4EpJIdbmwG3ZsNluor8L+/SsMw8DAIEiwXFtxwLT+FI13xeNxeGrky60m2QxbqK0dgAQPJCRD2zY1HosRXZIg1QBbVBS2qCicaak1sr/DYRhGqD8HbjeH/1tWcwy7vdo+N8Nms74MPZ5DL1yZ7RkGRsnn7khJCcs2q0NpnNWyXZcLXC6Iiwv79o8VSm6qWWnlJhA0CQRN7LbKf+kWZ2ayafbb5H48B/cv68q+Z4dcD+REQ060QW5JMgJWWdzhLymR+w2iTQcu0279lVTaKczhwOZwWL9EqSnYGzXA07Q5MU1akNSiNc0TGxHliMJmHH0D6uzYcdpq/q9fERGpHZTcVLPSyg1YI6Y8rn1l1KDPR8HiJfi3b8O/ew+BPbvx7trJrq1ryd+xleRtedhMcGM1na5sBt+0t7G4jYGRnEhaTAPSYtJIjU4lLTqN5tFp1PPUI8mdRGJUIslRyUQ7outcFUNERORglNxUs9IOxWD1u/Fgp+i338h6bwY5s2cTyM4ut46nZAJY3dhgTbcGeE/vTnrLrgxNbs8/k9oQ7ayZZgEREZHaRslNNSu9t1Ssr4DsqVPZ8+Fsin79NfS+NymGNalBMt1F5ERDdrSBkZTI8a160fWkDAa2OwWnXU0wIiIilaXkppoZhsGgDd9w9Y+zyf+opFe904nZpzuvNFvP3LSdmDaDaEccZ6efzeCWf6FbWrejsq+LiIhIbaDkppr5Nmzgmh/fxxEMYLRsTf3LLubTNkU8vvpF/EE/adENuL3b7fRr1g+PIzyjDURERI5lSm6q2Y4Jj+IIBlia2pb2Lz7Lc6sfZ8GqBQCc0fQMHur9EAnuhAhHKSIiUncoualGufPnk7dgAX6bnf+cdCJ8M4y93l04bU7u6nEXl7e9XCOZREREwkzJTTUJ+nzsmDABgE87t2dPx+kYXpP0+HSeOP0J2iW3i3CEIiIidZOSm2qyZ/LrFG/chL1+CtNPy8cwTHrUP5PnzpqgYdwiIiLVSENyqkHxjh3smjQJgLQxYyjwWNeyObPBpUpsREREqpmSm2qQ+cSTmAUFeLp2xX3eAIK2HADiHfUjHJmIiEjdp+QmzAqWLiXngw/AMEj7x73sKNgBgBl04iA2wtGJiIjUfUpuwsgMBNj+z4cBSLz0UjzHH8+2/G0ABIuTWLcrP5LhiYiIHBOU3ITLnvVk3XIy3t9+w5aQQP3bbwNgW56V3JjFiXy9ZlckIxQRETkmKLkJE7/XYOfXVt+a+jdfjyMpCWC/yk0i32/MotAXiFiMIiIixwIlN2Hi31uAzQ3uxGKS+p0Ymr81bysAsfYUfIEgSzbsiVSIIiIixwQlN2ES1aEDx13ThCan7sHI3hCavz1/OwBtU5oBsHCtmqZERESqk5KbMLKltsQVG4A960LztuZblZuTmrQEYKH63YiIiFQrJTfhlHyc9ViS3ATNYKhy0691WwB+2ZpDVoEvIuGJiIgcC5TchFOyVZ0pTW52F+6mOFiMzbDRLrUJbdJiMU1YtHZ3BIMUERGp25TchNOfKjelI6Xqe+rjtDk5pWUKgIaEi4iIVKOjIrl5/vnnSU9PJyoqip49e7J48eKDLv/000/Ttm1bPB4PTZs25Y477qCoqKiGoj2IeiXJTe428OWH+ts0im0EQO9WVnLzjSo3IiIi1Sbiyc3bb7/N6NGjuf/++/n+++/p0qULAwYMIDMzs8Llp06dyj333MP999/PypUreeWVV3j77bf5+9//XsORV8CTZE0Ae9azPc/qb9MgpgEAPY9Lxm4zWL8rny1ZhZGKUkREpE6LeHIzceJErrvuOq6++mo6dOjApEmTiI6O5tVXX61w+W+++YbevXtz5ZVXkp6eztlnn80VV1xxyGpPjdmvaSpUuYmxKjfxUU46N0kANGpKRESkukQ0ufH5fCxbtoz+/fuH5tlsNvr378+iRYsqXOeUU05h2bJloWRm3bp1fPTRR5x77rkVLu/1esnJySkzVatQp+K1oT43DWMaht7uXdLvRsmNiIhI9YhocrNr1y4CgQBpaWll5qelpbF9+/YK17nyyit58MEHOfXUU3E6nbRs2ZK+ffsesFlqwoQJJCQkhKamTZuG/TjK2K9yU3pfqYax+yU3+/W7MU2zemMRERE5BkW8WepwzZ8/n0ceeYQXXniB77//nhkzZvDhhx/y0EMPVbj82LFjyc7ODk2bN2+u3gBDyc36Cis3JzZPJMppY2eul9WZedUbi4iIyDHIEcmdp6SkYLfb2bFjR5n5O3bsoEGDBhWuc9999/HXv/6Va6+9FoBOnTqRn5/P9ddfz7333ovNVjZfc7vduN3u6jmAitSzmqXy96wlp551evdPbtwOOz3Sk/lq9S6+Xr2LNmlxNRebiIjIMSCilRuXy0W3bt2YN29eaF4wGGTevHn06tWrwnUKCgrKJTB2ux3g6GjmKancbCvcCUCcK45YV2yZRfY1TanfjYiISLhFtHIDMHr0aIYNG0b37t056aSTePrpp8nPz+fqq68GYOjQoTRu3JgJEyYAkJGRwcSJE+natSs9e/ZkzZo13HfffWRkZISSnIiKToaoRLYa1nV3SkdK7a+0U/G36/bgDwRx2Gtd66CIiMhRK+LJzWWXXcbOnTsZN24c27dv54QTTmDOnDmhTsabNm0qU6n5xz/+gWEY/OMf/2DLli3Ur1+fjIwMHn744UgdQnnJx7E993egbJNUqQ6N4kmMdpJVUMwPf2TTrXlSTUcoIiJSZxnmUdGWU3NycnJISEggOzub+Pj46tnJ9Gt4estcXklM4Ip2V/D3nuVHct305jI+/nk7d57Vhlv6ta6eOEREROqIw/n+VntIdajXkm2O8p2J91fa70b3mRIREQkvJTfVIfk4tjms/j/7X+Nmf6XJzfJNWRT4/DUWmoiISF2n5KY6JB+6cpNeL5pGCVH4AkGWbNhbk9GJiIjUaUpuqkFxYjMyS0ZuNXInV7iMYRj7mqZW76yx2EREROo6JTfVYCd+goaB0zSpV3jge1md0S4VgLeXbCarwFdT4YmIiNRpSm6qwdaS2y408Pux7Vl/wOUGHN+Atmlx5BT5eWH+2poKT0REpE5TclMNQveU8gdgz7oDLme3GdxzbjsAJi/cwOY9BTUSn4iISF2m5KYa7Etu/AdNbgD6tqnPKS3r4QsEmTj395oIT0REpE5TclMNylZuDt7cZBgGYwe2B2Dm8i38vCW72uMTERGpy5TcVINteVZy08jvh4P0uSnVqUkCF5xg3YNqwscrj44bgIqIiNRSSm6qwbb9OhST/QcUFx1ynTFnt8Vlt7FwzW6+XK2rFouIiFSVkpswM00zlNw0snkAE/ZuOOR6TZOjGdqrOQATPlpJIKjqjYiISFUouQmzbG82hf5CABokWMnKoToVlxp1Zivioxz8tj2Xmcu3VFeIIiIidZqSmzArrdrUi6qHO7mlNfMQnYpLJUa7GHlGKwCe+nQVRcWBaolRRESkLlNyE2Zb87cCJfeUSj7OmlnJyg3AsFPSaZzoYVt2Ea8t3FANEYqIiNRtSm7CbHv+dqDkbuD1Sis3lU9uopx27jy7DQDPfb6aldsOfPsGERERKU/JTZhtzaugcrO78skNwKATGtOzRTL5vgDDXl2sKxeLiIgcBiU3YRa6gN/+yU32ZvB7K70Nm83gpaHdaZsWR2aul2GvLmZPvm6sKSIiUhlKbsKs9AJ+DWMbQkx9cMVR2eHg+0vwOHl9xEk0TvSwblc+V09eQoHPH/6ARURE6hglN2FWpnJjGJDcwnrjMPrdlGqQEMXrI04iMdrJD5uzuHnK9xQHguEMV0REpM5RchNG3oCX3UW7AWgUY91OoSqdivfXKjWWV4f3IMppY/6qndz93o+6PYOIiMhBKLkJo9KRUh6HhwR3gjUz1Km4cte6qciJzZJ4YciJ2G0GM77fwqNzfjvSUEVEROosJTdhtP9IKcMwrJlVuNZNRc5sl8ajgzsB8O8F67jnvR8p9OkifyIiIn+m5CaMQte4iWm4b2bykTVL7e+S7k35x3ntMQyYtmQzGc99revgiIiI/ImSmzAKXZ04dv/kZv/h4Ec+nPvaPscx5ZqepMa5WZOZxwXPL+SNRRvUD0dERKSEkpswCg0D379yE5sKrlgwg5C1MSz7OaVVCh/f1ocz26Xi8wcZ9/4v3PDfZWQV6Fo4IiIiSm7CqMww8FL7Dwff/F3Y9lUv1s0rw7oz7vwOuOw2Pv11BwOf+YoFv+8M2z5ERERqIyU3YVRhcgPQ9jzr8ZO/Q9amsO3PMAxGnNqCGTefQouUGLZlFzHs1cVc9fJ3/LwlO2z7ERERqU2U3IRJ0AyGOhQ3im1U9s0+d0Lj7lCUDdNHQKA4rPvu2DiBD245lRG9W+C0G3y9Zhfn/+trbn1rOZt2675UIiJybFFyEya7C3dTHCzGZtioH12/7JsOF1z8KrgT4I8l8PlDYd9/jNvBuIwOfH5nXwadYCVXs3/YSr+J83lg9i/szqv8va1ERERqM8M8xobZ5OTkkJCQQHZ2NvHx8WHb7q7CXbz282vkF+fzwCkPVLzQr7Phnb9az4dMh9ZnhW3/f/bzlmwem/MbX63eBYDLYePsDmlcdGIT+rROwWFXXisiIrXH4Xx/HxXfcM8//zzp6elERUXRs2dPFi9efNDls7KyGDlyJA0bNsTtdtOmTRs++uijGoq2YimeFO7qcdeBExuADn+BHtdZz2feADlbqy2ejo0T+O81PXnzmp50bpKAzx/kgx+3cfXkJfR69HMe/vBXXSNHRETqpIhXbt5++22GDh3KpEmT6NmzJ08//TTvvvsuq1atIjU1tdzyPp+P3r17k5qayt///ncaN27Mxo0bSUxMpEuXLofcX3VVbiqtuAhe6Q/bf4LmvWHobLA7qnWXpmnyy9Ycpi/7g9k/bGVP/r4h4x0axnP5SU0Z1LUx8VHOao1DRESkqg7n+zviyU3Pnj3p0aMHzz33HADBYJCmTZtyyy23cM8995RbftKkSTzxxBP89ttvOJ2H/2Uc8eQGYNcaeOl08OXB6XfDGX+vsV0XB4LMX7WT95b9wbzfdlAcsD7+KKeNjM6NuKJnM7o2Tdx3+wgREZGjQK1Jbnw+H9HR0UyfPp1BgwaF5g8bNoysrCzef//9cuuce+65JCcnEx0dzfvvv0/9+vW58sorufvuu7Hb7eWW93q9eL37OtPm5OTQtGnTyCY3AD++CzOuBQy4fCq0O7fGQ9ib72PWii1M/W4TqzPzQvPbNYjjyp7NuKBLYxKiVc0REZHIqzV9bnbt2kUgECAtLa3M/LS0NLZv317hOuvWrWP69OkEAgE++ugj7rvvPp566in++c9/Vrj8hAkTSEhICE1NmzYN+3FUSedLoOtfAROmXQGzboaCPTUaQlKMi6t7t+DTO07jvZt6MfjExrgdNn7bnsu493+h+8Nzufq1xby37A9yisI7fF1ERKS6RLRys3XrVho3bsw333xDr169QvP/9re/sWDBAr77rvwVfdu0aUNRURHr168PVWomTpzIE088wbZt28otf9RWbsDqf/PpvbDkFcCE6HpwzqPQ6RLrysYRkF1QzMzlfzBtyWZ+254bmu+y2zitTQrnd27EGe1SSfCooiMiIjXncCo31duT9RBSUlKw2+3s2LGjzPwdO3bQoEGDCtdp2LAhTqezTBNU+/bt2b59Oz6fD5fLVWZ5t9uN2+0Of/Dh4IyC856CzpfB7Fth50qYcR388BacN3HfbRtqUEK0k+G9WzC8dwvWZOby4Y/b+eDHrazOzOOzlZl8tjITgEYJUbRMjaV1ahytUmNpnRZL69RYEqNdh9iDiIhI9YpocuNyuejWrRvz5s0L9bkJBoPMmzePUaNGVbhO7969mTp1KsFgEJvNalX7/fffadiwYbnEptZoehLc8CV88ywseBzWfg4v9IL+D8DJN0YsrFapcdzWP47b+rfm9x25fPDjNj78cStrd+azNbuIrdlFoevolOrUOIH+7dPo3yGVDg3j1TFZRERqXMRHS7399tsMGzaMf//735x00kk8/fTTvPPOO/z222+kpaUxdOhQGjduzIQJEwDYvHkzxx9/PMOGDeOWW25h9erVjBgxgltvvZV77733kPs7KkZLHczutfC/22DDV9bri1+FjhdFNqY/ySrwsSYzjzWZeawueVyTmceWrMIyyzVKiKJ/hzT6tU+jZ4tkopzlO3yLiIhURq0ZLVXqueee44knnmD79u2ccMIJPPvss/Ts2ROAvn37kp6ezuTJk0PLL1q0iDvuuIMVK1bQuHFjrrnmmgOOlvqzoz65ATBNmDvOquS44uCGBVCvZaSjOqSduV6++C2TuSt38NXqnRQVB0Pvuew2OjdJoHt6Mj3Sk+jWPElNWCIiUmm1LrmpSbUiuQEI+OGNC2Dj15DWCa6dC05PpKOqtKLiAAvX7OKzlZl8/tsOduSUv7dVm7RYTmiaSIuUWFqkRJOeEkPz5Bg8LlV4RESkLCU3B1FrkhuAnG0w6VQo2AXdhkPGM5GOqEpM02Tj7gKWbNjD0g17WbJxD+t25h9w+QbxUaSnRNOuQTwdGsbToVE8rVJj1awlInIMU3JzELUquQFY+wX890LAhMEvW9fHqQN25XlZumEvv27LYePufDbsymf9rnxyivwVLm+3GbSqH0v7hnE0SvQQ43YQ7bIT43YQ43IQ7bZTP9ZN+4bx2G3qxCwiUtcouTmIWpfcAHzxCCx4DJwxcP18qN8m0hFVC9M0ySooZv3ufNZm5vHb9lx+3ZrDyu05ZBVU7iKCcVEOTj6uHr1b1qN3qxRapcZqxJaISB2g5OYgamVyEwxY/W82fAWpHeDaeeCKjnRUNcY0TbZlF7FyWw4rt+WwO99HvtdPvi9AQcljvtfPpj0F5P6p8lM/zk2v4+rRKjWWxokeGid5aJzooUFCFE57RC/QLSIih0HJzUHUyuQGIHeH1f8mPxNOuAoGPR/piI46/kCQX7bmsHDtLhat3c2SDXvKjNjan82AtPgoGiREkRrnpn6cm9Q463lqvJuGCR5apcYqARIROUoouTmIWpvcAKxbAP8dBGYQOlwAZz0ISemRjuqo5fUHWL4piyXr97B5bwFbs4rYklXIlqxCfP6Kk579uR02OjSKp0uTRDo3SaBzk0SOS4nBVkGfnmDQxDBQE5iISDVRcnMQtTq5AVj0PHz6DyvBsbvg5Juhz50QVQuPJUKCQZNd+V627C1kR46XnblFZOZ62ZnrJTPXS2ZuERt3l2/iAoh22Yly2ikOBAkETfwBE38wSNCEOLeD41JjaVU/lpapMbSqH0ur1FiaJUfjUAVIROSIKLk5iFqf3ADs+AU++Tusm2+9jqkPZ/7Dusu4TcOlwyEYNNmwO58f/8jmhz+y+OmPbH7emn3AZq6DsdsM6se6SYt3kxofRVq8m7S4KNLio2iS7CG9XgwN4qMqrAiJiIhFyc1B1InkBqyrGP/+iXVX8d1rrHlpHaHLFVC/LaS0hoRmYFPFIFz8gSAb9xQQDJrYbQZOuw27zcBhM7DbDHbn77stxdqd1uO6nfkUFgcOuW23w0bzetGk14shPSWG5Bjr6s2lv50m1hOnzUbTZA/N68XQvF400a6I3h5ORKTGKLk5iDqT3JTy+2DpKzD/USjKKvueIwrqtbaGjic0AVcsOKPBFWM9d0VDdAo06aEkqJoEgyY787zsyCliR471mFnyfFtOEZv3FLB5TwH+YNV+DdPi3VaikxyN02HD5w/i9Qfx+QMlj0Fi3Q7al1wM8fhG8TRO9KhvkIjUOkpuDqLOJTelCvbA0ldh+4+w83fYsxYCvsqt26Cz1Tm55RnVG6NUqDgQZGtWIRt2F7Bxd8nFDAv97J9/lD4t8gfZtMdarrLX/vmz+CgHHRrF0yYtDo/LjtNmK6lEGTjsNhw2A4/Lbl0cseRCiaWPsW4HidFOPE67EiQRqVFKbg6iziY3fxbwQ9ZG2PU77FwFeTvAlw/FBdZj6bRzFfhyrXVa9oOzxkODTpGNXSolq8AXSog27S7ABFwOGy67zXp02HA7bOzJ9/HL1hx+3ZrD6sxcigNH/ivvsttIiHaS4HGS6HES73Histuw2w2cNgO7zUqSHHYDf8CkyB+g0BegyB+kqDiAtziAx2XnpPRkTm5ZjxObJen2GiJyUEpuDuKYSW4qK383fPkELHkZgsWAAV0uhzPuhcSmkY5OwsznD7ImM49ftmazflc+Pn8Qf9CkOBDEHzApDlqPhcVWMpLv81PgLXn0BcgtKg5LcvRnLoeNE5sl0uu4FHq0SCI+yondZmAzDGwlQ+ztNoOgaRIMmgRMk0DQJBiEgGnidtholhxNjFt9kETqKiU3B6Hk5gD2rIN5D8EvM6zXdjcc1xfqtYTk40oeW1p9dzQi65hlmlbik1VQbE2FPrILiskpSXr8AStZCgTNUNLktFsVpCinvWSyEeWwszPPy7frdrNo7W4yc8vfNb4qUuPcpKfEkF7Pust8k6Ro8or8ZJYM98/cb+i/x2nnuPoxHFc/lpahx9hQZ26pW0zTpKg4SK63GLfdTrzHoabVWkbJzUEouTmELcvg03Gw8euK37e7IaUNNO0BTU+GpidZFxLUfxJSRaZpsm5XPovW7mbRut38+EcWPr917aBg0LSqNSXPMayh9XbDwFbyaLcZFPj87K1iH6Q/i4tykBLrJinaSXKMi6Rol/UY4yLKYcPpsOG0W81/TrutpK/Svqa40hF0pUP784r85Hn95BX5ySkqDj0v7UQeNE1Ms+SRfSPkSs5OmdgMY98x2wwDu419lxAwKVnf2p4JBIImXn8Qrz+wX2dz6xpNsW4HCR4n8R7rMaGkedFuM6yqmGkSCBKqlPkDQQqLAxQVlz5ak89vEhflICnaRVKMk8RoF0nRThI9Lor8gVBCuTOvJLnM84auIWWEjgsMDDAgtqRvV2yUgzi3g7go67U/aJJdaCXV2YX7pkJfAMOg5Hzsq/QZBhT6AuSWnn+vn8B+HfejnDbS4qNIi4siNd5NWnwUyTGuMpXB0ilomrgd9pK+aHaiS27WG+2y47TbrJ9P0wyd+6Bp9aUr/QPA+mPAx96S2IGSnx8D159+nkqblEubmN1O63HfyEwbdhuhx0JfkNyiYnKL/Naj109ukR+fP4jTXvrzaCv5GbV+bvJLzkfufj+b+V4/iTFO0uvFcFyKNWqzRcmUFOMit8hPTsk5zyksJqfIT15RMXa7DVfJcbjs9pLjMYhxO+iRnhyW38lSSm4OQslNJZgm/LEEtv9kVXR2r7U6KO9ZX9J09ScxqVaS06SHlfgkNYfE5uCOrfnY5ZiVXVDMht35bCjplL1hVz5bsgqJj3KSGu+mfpx1jaHUuCjqx7nJ9/pZtzOPtTvzWbvTGra/Jasw0och1cww/pxASnVIiXWz9B/9w7pNJTcHoeTmCAT8kL3ZGpG1eTFs/g62rqg44QHr4oJJ6Vai44oBM2D9rxIMlDwPQmwD6HmDlRCJRFihL8CWrAL25BezJ9/H3gIfe/J9oedef5Bif9DqoxQ08fmD+Pa7WnXQNPdrlgtimlYlIi7KQVyUM/Q81u3AYTcwsCoNGAYlDxgYoULo/pWN0opAYL9+R8GSfZUuY5Rsh5LtOGwGbsf+Hcytv6ztNquilF3yF3h2SUUhp6iYQMl1nPZVh6xHp93A47TjdtrxOO14XFbzosNuI6eopDKRX8zeAqtSsbfAh8dlp36sdb826zGK+rFu4j3O/c66GUo2AqZJgTdAbkk1Ic9bUpHw+nHYjFCFaf8pxu3YV90rOSelz2NcVgVo//PucdrxBYJk5njZkVsUukxDZk4Rewt8oWO3KmTWubIZBl5/kALfvhv2FpT0SfMHTKtvWMlyRkk/MSteF4nRTquSFW09T/S4MAxCPzvFgdKfKRNfYF91rbTatv/P2P5T6c9ZlNNOfFRJpavk5ywuyoHLbiNomhQH9l8+SCAIsW57yXnZ9zMZ7bKzK8/Hhl35rNuVz/pdeWzYVcD63VbfPJfdRnxJpS8+yjr3VkWtJPbSuAPWY1K0k6nXnRzW308lNweh5CbMiotg2wor2dn6vVXdydoIhXsrvw2bE078K/QZAwmNqy1UERE5PMGglXS5HbaI91FScnMQSm5qSGGWleTs3QB7N0LAC4YNDLv1aLMDBqz+ZN9tJOxu6H41nDoa4tIiF7uIiBx1lNwchJKbo9CGr+Hzh2HTN9Zrhwd6XAOt+lu3kohreOAOy0U5kLkSMn+1LlrY7nxVf0RE6iAlNweh5OYoZZpWBeeLh63OzPtzxVr3ykppCymtwJtnJTOZK60+QGUYcNzp0OVKaJ9h3WJCRERqPSU3B6Hk5ihnmrB6Lnz/unX15D3rrM7HBxPfGFLbg69gX/UHrKSowyDochkkNAWbw5rsTqtZzOa0qj2+PCth8uWBN9d6NE1ru4lNrdFguveWiEhEKbk5CCU3tYzfB3vXW7eR2PU77FoDTg+kdYDU4yG1HXiS9i2/Zz38+DasmGr1+QkHu9tq6kpoaiU7CU2txCehiTXFN1aFSESkmim5OQglN8eIYBA2LYIfpsLvn1r31Ar6IVBcvhLkiLKqPO7YkrulxwImZG+B3K3WkPVD8SRb6weKrWpQoHjfc8Ow+g3FNyqZGu97TOtoXf1ZF0EUETmow/n+1o1YpG6y2SC9tzX9Wem1doLFVtOU/SC/BoFiyNlq9e3J2mw9Zv9hTTlbrEdfHhTusaaKmJSs9+f+QSWiEqHxidC4OzTpDo27QUxK5Y7Tm2dVqLI2WcfljLI6ZIcePRCdDO64ym1PRKQOUHIjxx7DsBKagyU1pexO6wKDB7rIoGlCUbaV5PiLrOXtrpKp5HnQD7nbSxKirVZSlLPVSkh2/AxFWbD2c2sqFV3PqgZFJ+/3mGRVmbI2lQyxXw/5Oyt3zAnNrH5Jqe0htYP1mNDE2tau1bB7dUmz32qraS+xGbQ9B9oMtBKuiu4nFgxYV7He+I21btOToM05VqwiIhGkZimRSAoUw45fYMtS2PI9/LHUShQ4jF9LT5KVjNgc1kUV/YXlH49EdAq0GWAlLvGNYONC2LAQNn0L3uyyyxp2aH6KNSS/3XnhvbN8caGVULli1IwncgxSn5uDUHIjR73SSlBBSVPX/o/+IqviktTCurVFUjp4Eg++vYI9sPO3fcPnM1daCVVRlnWLjHqtS4baty65N1g6bPsRfv8YVn9WPoHZnysOmp1srbd+gVWJ2l/DLtC8d8md5VtZ/Yvim1Ru9FnBHiuB2rjQqg5t+8HqL2V3WdUsT9K+ilZsqnWpgPptoX47iGtw4AQoGLSOPRgAh9uqhtmdVUuYgkHw5lifWVFWyWO2dRHLomyrz1VSc0huaR27mgePDaZp9dWrqOJZ04IBq8Kbux3ydlhXj49KsH73o+tZTeCu2FrxB4OSm4NQciOC9Z9vceGhR3kFiq3E4vc51lSYBU17Wn2ZmveGBp3LNu/tWQ+rPoKVH1gduiuqQNndVrKT0Nh67nDt15TnsvpC/bHUSsaqyp0A9dtYCVVxIeTvgoJd1mPhnvKdxA2bleSUJjuOKKu/0v6PDrfVvyqUvGRZF5E8nCpbbJqV6CQfZ22Xki/B0i9DTKsCV9pfyhkFzmhr/zaHtc/SZLdwLxTstebZneCOh6h469ij4q3XNnv5xKso27psgitm33JRCfvWd8VY+3TFlMQQY/2cmEHr/O1/LvN3WnH4i8DvtZK50seAz/p83XH77afk0RFlXbXcXzoV7Vu39N5zQf9+zwPWsTg81ufgLHks7V/mjrO2646zJlesFX9xQdnjLipJRIvz93X495fEWnoV9Yo6/8c2sC4TkbutZNpeMm2zzm1xIfjyrcfiQmv7ZtD6eXbFlJzDkvPoLKk87n9spffaCwZLjtu/3zkomRfyp5+30CUuSn+HSp77iyB3h/VZHWpQhN1tJTlRiSXnMHa/cxlnbdOXXzLl7XteXGh9Fq7S44vdd+6jk6H3bZX/3agEJTcHoeRGpIbk7YQ1c60q0Z51sHvNge8sfyApbaxmrmanQPNeVsWmcO9+X+4lX/Q5W63rIlX22kjh5oiyvhiiEqxKWlSCNRl2q2/U7rXWl4xIJBg263pdsalWpbMoGwp2WwnqkTZbH0hsGoz5Payb1GgpEYm82PpwwpVl55XeWX7PWuuvytK/8EN/8Rdbf2U26ATNelnb+DN37MH78vi9VjKx8zcrsXDF7iu/R6dYj55kq9oR8Fl/fZZWD/zeivssFRdZ77ti90tgEvc9d7gPfT4Ks6zj3r3Oiivgs750MEruu2ZYz4P+P+27ZAr6rX3u3xznSbL2H/Dvax7z5lgVCm+OVRXwJO6rzpTG7PRYf3lXtI6vwKo8FBeWfQ77NWXUt85jTH0rBme0VS1wuKwqQGln+oDXqniUbrv0ecC7r2rniCpZ123Ns9lLqhF2Kzm0OaxmzGBgv8+q5LH03PhyrW2HppKLcrpi9jv20qmkOmV3lZ/MgFWNydm6r/N/9harOScqwWrujE2zqjtxDaxHT1JJRaZ0Kqlk2JxW5ciXb51DX751Pn151rkMHd/+j4a1Xunx738eKmo2Mk0r5oDf+nkK7ncJCpvTukdfbAPrszpQE5kvf181rihn34VMvbkln1me9bMXqs7E7KvOODzWZ1Fa0fHuV9VxRh36d6IaqXIjIiIiR73D+f4+Kq4p//zzz5Oenk5UVBQ9e/Zk8eLFlVpv2rRpGIbBoEGDqjdAERERqTUinty8/fbbjB49mvvvv5/vv/+eLl26MGDAADIzMw+63oYNGxgzZgx9+vSpoUhFRESkNoh4cjNx4kSuu+46rr76ajp06MCkSZOIjo7m1VdfPeA6gUCAIUOGMH78eI477rgajFZERESOdhFNbnw+H8uWLaN///6heTabjf79+7No0aIDrvfggw+SmprKNddcc8h9eL1ecnJyykwiIiJSd0U0udm1axeBQIC0tLQy89PS0ti+fXuF63z99de88sor/Oc//6nUPiZMmEBCQkJoato0jFdMFRERkaNOxJulDkdubi5//etf+c9//kNKSuVuLDh27Fiys7ND0+bNB7h5oYiIiNQJEb3OTUpKCna7nR07dpSZv2PHDho0aFBu+bVr17JhwwYyMjJC84JB68qLDoeDVatW0bJlyzLruN1u3O5KXINCRERE6oSIVm5cLhfdunVj3rx5oXnBYJB58+bRq1evcsu3a9eOn376iRUrVoSmv/zlL5xxxhmsWLFCTU4iIiIS+SsUjx49mmHDhtG9e3dOOukknn76afLz87n66qsBGDp0KI0bN2bChAlERUXRsWPHMusnJiYClJsvIiIix6aIJzeXXXYZO3fuZNy4cWzfvp0TTjiBOXPmhDoZb9q0CVtl7iAsIiIigm6/EOlwREREpBJq3e0XRERERMJFyY2IiIjUKUpuREREpE6JeIfimlbaxUi3YRAREak9Sr+3K9NV+JhLbnJzcwF0TRwREZFaKDc3l4SEhIMuc8yNlgoGg2zdupW4uDgMwwjrtnNycmjatCmbN28+5kZiHcvHDsf28R/Lxw7H9vEfy8cOOv6aPn7TNMnNzaVRo0aHvETMMVe5sdlsNGnSpFr3ER8ff0z+oMOxfexwbB//sXzscGwf/7F87KDjr8njP1TFppQ6FIuIiEidouRGRERE6hQlN2Hkdru5//77j8m7kB/Lxw7H9vEfy8cOx/bxH8vHDjr+o/n4j7kOxSIiIlK3qXIjIiIidYqSGxEREalTlNyIiIhInaLkRkREROoUJTdh8vzzz5Oenk5UVBQ9e/Zk8eLFkQ6pWnz55ZdkZGTQqFEjDMNg1qxZZd43TZNx48bRsGFDPB4P/fv3Z/Xq1ZEJNswmTJhAjx49iIuLIzU1lUGDBrFq1aoyyxQVFTFy5Ejq1atHbGwsF110ETt27IhQxOH14osv0rlz59AFu3r16sXHH38cer8uH/ufPfrooxiGwe233x6aV5eP/4EHHsAwjDJTu3btQu/X5WMH2LJlC1dddRX16tXD4/HQqVMnli5dGnq/Lv+/l56eXu6zNwyDkSNHAkfvZ6/kJgzefvttRo8ezf3338/3339Ply5dGDBgAJmZmZEOLezy8/Pp0qULzz//fIXvP/744zz77LNMmjSJ7777jpiYGAYMGEBRUVENRxp+CxYsYOTIkXz77bfMnTuX4uJizj77bPLz80PL3HHHHfzvf//j3XffZcGCBWzdupXBgwdHMOrwadKkCY8++ijLli1j6dKlnHnmmVxwwQX88ssvQN0+9v0tWbKEf//733Tu3LnM/Lp+/Mcffzzbtm0LTV9//XXovbp87Hv37qV37944nU4+/vhjfv31V5566imSkpJCy9Tl//eWLFlS5nOfO3cuAJdccglwFH/2phyxk046yRw5cmTodSAQMBs1amROmDAhglFVP8CcOXNm6HUwGDQbNGhgPvHEE6F5WVlZptvtNt96660IRFi9MjMzTcBcsGCBaZrWsTqdTvPdd98NLbNy5UoTMBctWhSpMKtVUlKS+fLLLx8zx56bm2u2bt3anDt3rnn66aebt912m2madf+zv//++80uXbpU+F5dP/a7777bPPXUUw/4/rH2/95tt91mtmzZ0gwGg0f1Z6/KzRHy+XwsW7aM/v37h+bZbDb69+/PokWLIhhZzVu/fj3bt28vcy4SEhLo2bNnnTwX2dnZACQnJwOwbNkyiouLyxx/u3btaNasWZ07/kAgwLRp08jPz6dXr17HzLGPHDmS8847r8xxwrHx2a9evZpGjRpx3HHHMWTIEDZt2gTU/WOfPXs23bt355JLLiE1NZWuXbvyn//8J/T+sfT/ns/n480332TEiBEYhnFUf/ZKbo7Qrl27CAQCpKWllZmflpbG9u3bIxRVZJQe77FwLoLBILfffju9e/emY8eOgHX8LpeLxMTEMsvWpeP/6aefiI2Nxe12c+ONNzJz5kw6dOhwTBz7tGnT+P7775kwYUK59+r68ffs2ZPJkyczZ84cXnzxRdavX0+fPn3Izc2t88e+bt06XnzxRVq3bs0nn3zCTTfdxK233srrr78OHFv/782aNYusrCyGDx8OHN0/98fcXcFFwmHkyJH8/PPPZfodHAvatm3LihUryM7OZvr06QwbNowFCxZEOqxqt3nzZm677Tbmzp1LVFRUpMOpcQMHDgw979y5Mz179qR58+a88847eDyeCEZW/YLBIN27d+eRRx4BoGvXrvz8889MmjSJYcOGRTi6mvXKK68wcOBAGjVqFOlQDkmVmyOUkpKC3W4v1zt8x44dNGjQIEJRRUbp8db1czFq1Cg++OADvvjiC5o0aRKa36BBA3w+H1lZWWWWr0vH73K5aNWqFd26dWPChAl06dKFZ555ps4f+7Jly8jMzOTEE0/E4XDgcDhYsGABzz77LA6Hg7S0tDp9/H+WmJhImzZtWLNmTZ3/7Bs2bEiHDh3KzGvfvn2oWe5Y+X9v48aNfPbZZ1x77bWheUfzZ6/k5gi5XC66devGvHnzQvOCwSDz5s2jV69eEYys5rVo0YIGDRqUORc5OTl89913deJcmKbJqFGjmDlzJp9//jktWrQo8363bt1wOp1ljn/VqlVs2rSpThx/RYLBIF6vt84fe79+/fjpp59YsWJFaOrevTtDhgwJPa/Lx/9neXl5rF27loYNG9b5z753797lLvnw+++/07x5c6Du/79X6rXXXiM1NZXzzjsvNO+o/uwj2p25jpg2bZrpdrvNyZMnm7/++qt5/fXXm4mJieb27dsjHVrY5ebmmsuXLzeXL19uAubEiRPN5cuXmxs3bjRN0zQfffRRMzEx0Xz//ffNH3/80bzgggvMFi1amIWFhRGO/MjddNNNZkJCgjl//nxz27ZtoamgoCC0zI033mg2a9bM/Pzzz82lS5eavXr1Mnv16hXBqMPnnnvuMRcsWGCuX7/e/PHHH8177rnHNAzD/PTTT03TrNvHXpH9R0uZZt0+/jvvvNOcP3++uX79enPhwoVm//79zZSUFDMzM9M0zbp97IsXLzYdDof58MMPm6tXrzanTJliRkdHm2+++WZombr8/55pWiOAmzVrZt59993l3jtaP3slN2Hyr3/9y2zWrJnpcrnMk046yfz2228jHVK1+OKLL0yg3DRs2DDTNK1hkffdd5+ZlpZmut1us1+/fuaqVasiG3SYVHTcgPnaa6+FliksLDRvvvlmMykpyYyOjjYvvPBCc9u2bZELOoxGjBhhNm/e3HS5XGb9+vXNfv36hRIb06zbx16RPyc3dfn4L7vsMrNhw4amy+UyGzdubF522WXmmjVrQu/X5WM3TdP83//+Z3bs2NF0u91mu3btzJdeeqnM+3X5/z3TNM1PPvnEBCo8pqP1szdM0zQjUjISERERqQbqcyMiIiJ1ipIbERERqVOU3IiIiEidouRGRERE6hQlNyIiIlKnKLkRERGROkXJjYiIiNQpSm5E5JhgGAazZs2KdBgiUgOU3IhItRo+fDiGYZSbzjnnnEiHdliWLFkSuhvy1q1b8Xg8+Hy+CEclIhVxRDoAEan7zjnnHF577bUy89xud4SiqZpFixbRu3dvAL766iu6d++Oy+WKcFQiUhFVbkSk2rndbho0aFBmSkpKCr1vGAYvvvgiAwcOxOPxcNxxxzF9+vQy2/jpp58488wz8Xg81KtXj+uvv568vLwyy7z66qscf/zxuN1uGjZsyKhRo8q8v2vXLi688EKio6Np3bo1s2fPrvQxfPPNN6Hk5uuvvw49F5Gjj5IbETkq3HfffVx00UX88MMPDBkyhMsvv5yVK1cCkJ+fz4ABA0hKSmLJkiW8++67fPbZZ2WSlxdffJGRI0dy/fXX89NPPzF79mxatWpVZh/jx4/n0ksv5ccff+Tcc89lyJAh7Nmz54Axff311yQmJpKYmMj06dO59957SUxMZNKkSTz77LMkJiby6KOPVs8JEZGqi/SdO0Wkbhs2bJhpt9vNmJiYMtPDDz8cWgYwb7zxxjLr9ezZ07zppptM0zTNl156yUxKSjLz8vJC73/44YemzWYzt2/fbpqmaTZq1Mi89957DxgHYP7jH/8Ivc7LyzMB8+OPPz7gOoWFheb69evNjz/+2ExKSjLXrVtnLl261HS5XObKlSvN9evXm3v37j2s8yEi1U99bkSk2p1xxhm8+OKLZeYlJyeXed2rV69yr1esWAHAypUr6dKlCzExMaH3e/fuTTAYZNWqVRiGwdatW+nXr99B4+jcuXPoeUxMDPHx8WRmZh5w+aioKNLT03nnnXcYOHAgLVq04JtvvqFPnz60a9fuoPsSkchRciMi1S4mJqZcE1E4eTyeSi3ndDrLvDYMg2AweMDlY2NjAfB6vdhsNt5//318Ph+maRIbG0ufPn34+OOPqx64iFQL9bkRkaPCt99+W+51+/btAWjfvj0//PAD+fn5ofcXLlyIzWajbdu2xMXFkZ6ezrx588Ia04oVK1i6dCl2u5158+axYsUK6tWrxzvvvMOKFSt4+eWXw7o/EQkPVW5EpNp5vV62b99eZp7D4SAlJSX0+t1336V79+6ceuqpTJkyhcWLF/PKK68AMGTIEO6//36GDRvGAw88wM6dO7nlllv461//SlpaGgAPPPAAN954I6mpqQwcOJDc3FwWLlzILbfcUuW4W7VqxbfffktaWhqnnnoqmzZtIjc3l4yMDBwO/fcpcrTSb6eIVLs5c+bQsGHDMvPatm3Lb7/9Fno9fvx4pk2bxs0330zDhg1566236NChAwDR0dF88skn3HbbbfTo0YPo6GguuugiJk6cGFp/2LBhFBUV8X//93+MGTOGlJQULr744iOOff78+Zx22mkALFiwgF69eimxETnKGaZpmpEOQkSObYZhMHPmTAYNGhTpUESkDlCfGxEREalTlNyIiIhInaKGYxGJOLWOi0g4qXIjIiIidYqSGxEREalTlNyIiIhInaLkRkREROoUJTciIiJSpyi5ERERkTpFyY2IiIjUKUpuREREpE5RciMiIiJ1yv8D+BCUzmrsswsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Графіки тренування моделі\n",
    "plt.figure()\n",
    "plt.plot(H.history['loss'], label='train_loss')\n",
    "plt.plot(H.history['val_loss'], label='val_loss')\n",
    "plt.plot(H.history['accuracy'], label='train_acc')\n",
    "plt.plot(H.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Ukrainian_OCR_tf_2.1_lower_case_scale_reduction.h5',save_format=\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('Ukrainian_OCR_tf_2.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m# evaluate the network\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[INFO] evaluating network...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(testX, batch_size\u001b[39m=\u001b[39mBS)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(classification_report(testY\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m     11\u001b[0m \tpredictions\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), target_names\u001b[39m=\u001b[39mlabelNames))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# define the list of label names\n",
    "\n",
    "labelNames = \"абвгґдеєжзиіїйклмнопрстуфхцчшщьюя1234567890№%@,.?:;\\\"!()-'\"\n",
    "labelNames = [l for l in labelNames]\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import build_montages\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "images = []\n",
    "# randomly select a few testing characters\n",
    "\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(66,)):\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    "    output += label\n",
    "    image = (testX[i] * 255).astype(\"uint8\")\n",
    "    color = (0, 255, 0)\n",
    "    color = (0, 0, 255)\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    img_pil = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=34)\n",
    "    draw.text((5, 20), label, font=font, fill=color)\n",
    "    image = np.array(img_pil)\n",
    "    images.append(image)\n",
    "  \n",
    "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
    "cv2.imshow('q',montage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'гЛЄРНезцХВЙжЮЕйткЗПццЗнТчХЧСрОРаФЬЩҐтИЖйИАОтЯмрЛЩ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
