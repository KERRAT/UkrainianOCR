{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset(datasetPath):\n",
    "\n",
    "  # List for storing data\n",
    "  data = []\n",
    "  \n",
    "  # List for storing labels\n",
    "  labels = []\n",
    "  \n",
    "  for row in open(datasetPath): #Openfile and start reading each row\n",
    "    #Split the row at every comma\n",
    "    row = row.split(\",\")\n",
    "    \n",
    "    #row[0] contains label\n",
    "    label = int(row[0])\n",
    "    \n",
    "    #Other all collumns contains pixel values make a saperate array for that\n",
    "    image = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
    "    \n",
    "    #Reshaping image to 28 x 28 pixels\n",
    "    image = image.reshape((32, 32))\n",
    "    \n",
    "    #append image to data\n",
    "    data.append(image)\n",
    "    \n",
    "    #append label to labels\n",
    "    labels.append(label)\n",
    "    \n",
    "  #Converting data to numpy array of type float32\n",
    "  data = np.array(data, dtype='float32')\n",
    "  \n",
    "  #Converting labels to type int\n",
    "  labels = np.array(labels, dtype=\"int\")\n",
    "  \n",
    "  return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Data, Labels) = load_dataset(\"../data/uaset_without_columns.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Data, Labels) = load_dataset(\"../data/uaset_extended_lower_case_size_reduction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Each image in the A-Z and MNIST digts datasets are 28x28 pixels;\n",
    "# However, the architecture we're using is designed for 32x32 images,\n",
    "# So we need to resize them to 32x32\n",
    "\n",
    "Data = [cv2.resize(image, (32, 32)) for image in Data]\n",
    "Data = np.array(Data, dtype=\"float32\")\n",
    "\n",
    "# add a channel dimension to every image in the dataset and scale the\n",
    "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
    "\n",
    "Data = np.expand_dims(Data, axis=-1)\n",
    "Data /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "le = LabelBinarizer()\n",
    "Labels = le.fit_transform(Labels)\n",
    "\n",
    "counts = Labels.sum(axis=0)\n",
    "\n",
    "# account for skew in the labeled data\n",
    "classTotals = Labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "  classWeight[i] = classTotals.max() / classTotals[i]\n",
    "  \n",
    "(trainX, testX, trainY, testY) = train_test_split(Data,\n",
    "\tLabels, test_size=0.30, stratify=Labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "rotation_range=5,\n",
    "zoom_range=0.05,\n",
    "width_shift_range=0.10,\n",
    "height_shift_range=0.10,\n",
    "shear_range=0.1,\n",
    "horizontal_flip=False,\n",
    "fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class ResNet:\n",
    "\t@staticmethod\n",
    "\tdef residual_module(data, K, stride, chanDim, red=False,\n",
    "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "\t\t# the shortcut branch of the ResNet module should be\n",
    "\t\t# initialize as the input (identity) data\n",
    "\t\tshortcut = data\n",
    "\n",
    "\t\t# the first block of the ResNet module are the 1x1 CONVs\n",
    "\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(data)\n",
    "\t\tact1 = Activation(\"relu\")(bn1)\n",
    "\t\tconv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "\t\t# the second block of the ResNet module are the 3x3 CONVs\n",
    "\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(conv1)\n",
    "\t\tact2 = Activation(\"relu\")(bn2)\n",
    "\t\tconv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n",
    "\t\t\tpadding=\"same\", use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act2)\n",
    "\n",
    "\t\t# the third block of the ResNet module is another set of 1x1\n",
    "\t\t# CONVs\n",
    "\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(conv2)\n",
    "\t\tact3 = Activation(\"relu\")(bn3)\n",
    "\t\tconv3 = Conv2D(K, (1, 1), use_bias=False,\n",
    "\t\t\tkernel_regularizer=l2(reg))(act3)\n",
    "\n",
    "\t\t# if we are to reduce the spatial size, apply a CONV layer to\n",
    "\t\t# the shortcut\n",
    "\t\tif red:\n",
    "\t\t\tshortcut = Conv2D(K, (1, 1), strides=stride,\n",
    "\t\t\t\tuse_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "\t\t# add together the shortcut and the final CONV\n",
    "\t\tx = add([conv3, shortcut])\n",
    "\n",
    "\t\t# return the addition as the output of the ResNet module\n",
    "\t\treturn x\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes, stages, filters,\n",
    "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9, dataset=\"cifar\"):\n",
    "\t\t# initialize the input shape to be \"channels last\" and the\n",
    "\t\t# channels dimension itself\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "\n",
    "\t\t# set the input and apply BN\n",
    "\t\tinputs = Input(shape=inputShape)\n",
    "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(inputs)\n",
    "\n",
    "\t\t# check if we are utilizing the CIFAR dataset\n",
    "\t\tif dataset == \"cifar\":\n",
    "\t\t\t# apply a single CONV layer\n",
    "\t\t\tx = Conv2D(filters[0], (3, 3), use_bias=False,\n",
    "\t\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "\n",
    "\t\t# check to see if we are using the Tiny ImageNet dataset\n",
    "\t\telif dataset == \"tiny_imagenet\":\n",
    "\t\t\t# apply CONV => BN => ACT => POOL to reduce spatial size\n",
    "\t\t\tx = Conv2D(filters[0], (5, 5), use_bias=False,\n",
    "\t\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "\t\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\t\tmomentum=bnMom)(x)\n",
    "\t\t\tx = Activation(\"relu\")(x)\n",
    "\t\t\tx = ZeroPadding2D((1, 1))(x)\n",
    "\t\t\tx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "\t\t# loop over the number of stages\n",
    "\t\tfor i in range(0, len(stages)):\n",
    "\t\t\t# initialize the stride, then apply a residual module\n",
    "\t\t\t# used to reduce the spatial size of the input volume\n",
    "\t\t\tstride = (1, 1) if i == 0 else (2, 2)\n",
    "\t\t\tx = ResNet.residual_module(x, filters[i + 1], stride,\n",
    "\t\t\t\tchanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "\t\t\t# loop over the number of layers in the stage\n",
    "\t\t\tfor j in range(0, stages[i] - 1):\n",
    "\t\t\t\t# apply a ResNet module\n",
    "\t\t\t\tx = ResNet.residual_module(x, filters[i + 1],\n",
    "\t\t\t\t\t(1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "\t\t# apply BN => ACT => POOL\n",
    "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "\t\t\tmomentum=bnMom)(x)\n",
    "\t\tx = Activation(\"relu\")(x)\n",
    "\t\tx = AveragePooling2D((8, 8))(x)\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tx = Flatten()(x)\n",
    "\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "\t\tx = Activation(\"softmax\")(x)\n",
    "\n",
    "\t\t# create the model\n",
    "\t\tmodel = Model(inputs, x, name=\"resnet\")\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 120\n",
    "INIT_LR = 1\n",
    "BS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3),\n",
    "\t(64, 64, 128, 256), reg=0.0005)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 1)    4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   576         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   1024        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2304        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   1024        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   4096        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   1024        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2304        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1024        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2304        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 64)   1024        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           conv2d_10[0][0]                  \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 32)   2048        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9216        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 128)  4096        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  8192        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 128)  0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 32)   4096        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 128)  4096        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           conv2d_17[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 32)   4096        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 32)   9216        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 128)  4096        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 128)  0           conv2d_20[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   8192        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 64)     36864       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 256)    16384       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 256)    32768       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 256)    0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 256)    1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 64)     16384       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 64)     36864       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 256)    16384       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 256)    0           conv2d_27[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 64)     16384       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 64)     36864       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 256)    16384       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 256)    0           conv2d_30[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 256)    0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 57)           14649       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 57)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 332,541\n",
      "Trainable params: 328,379\n",
      "Non-trainable params: 4,162\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Додайте колбеки\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=12, verbose=1, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.001, verbose=1)\n",
    "\n",
    "callbacks_list = [early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 14s 95ms/step - loss: 4.4664 - accuracy: 0.1380 - val_loss: 2.6692 - val_accuracy: 0.2526 - lr: 1.0000\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 2.1305 - accuracy: 0.5986 - val_loss: 1.7585 - val_accuracy: 0.5753 - lr: 1.0000\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 1.2800 - accuracy: 0.7902 - val_loss: 0.8215 - val_accuracy: 0.8631 - lr: 1.0000\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 1.0525 - accuracy: 0.8409 - val_loss: 0.8530 - val_accuracy: 0.8433 - lr: 1.0000\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.9337 - accuracy: 0.8659 - val_loss: 0.7253 - val_accuracy: 0.8782 - lr: 1.0000\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.8495 - accuracy: 0.8841 - val_loss: 0.6532 - val_accuracy: 0.8978 - lr: 1.0000\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.7922 - accuracy: 0.8938 - val_loss: 0.6206 - val_accuracy: 0.9029 - lr: 1.0000\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.7670 - accuracy: 0.8994 - val_loss: 0.6252 - val_accuracy: 0.8985 - lr: 1.0000\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.7431 - accuracy: 0.9007 - val_loss: 0.6045 - val_accuracy: 0.9081 - lr: 1.0000\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.7239 - accuracy: 0.9062 - val_loss: 0.6022 - val_accuracy: 0.9029 - lr: 1.0000\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.7061 - accuracy: 0.9078 - val_loss: 0.5663 - val_accuracy: 0.9186 - lr: 1.0000\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.6876 - accuracy: 0.9108 - val_loss: 0.5612 - val_accuracy: 0.9218 - lr: 1.0000\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.6786 - accuracy: 0.9123 - val_loss: 0.5551 - val_accuracy: 0.9230 - lr: 1.0000\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.6697 - accuracy: 0.9133 - val_loss: 0.5949 - val_accuracy: 0.9122 - lr: 1.0000\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.6479 - accuracy: 0.9179 - val_loss: 0.5474 - val_accuracy: 0.9176 - lr: 1.0000\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 13s 88ms/step - loss: 0.6437 - accuracy: 0.9191 - val_loss: 0.5560 - val_accuracy: 0.9154 - lr: 1.0000\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.6375 - accuracy: 0.9178 - val_loss: 0.5354 - val_accuracy: 0.9159 - lr: 1.0000\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.6314 - accuracy: 0.9182 - val_loss: 0.5357 - val_accuracy: 0.9191 - lr: 1.0000\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.6203 - accuracy: 0.9222 - val_loss: 0.5362 - val_accuracy: 0.9208 - lr: 1.0000\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.6135 - accuracy: 0.9232 - val_loss: 0.5243 - val_accuracy: 0.9237 - lr: 1.0000\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.6170 - accuracy: 0.9196 - val_loss: 0.5320 - val_accuracy: 0.9178 - lr: 1.0000\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.6051 - accuracy: 0.9224 - val_loss: 0.5322 - val_accuracy: 0.9193 - lr: 1.0000\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.6021 - accuracy: 0.9225 - val_loss: 0.5276 - val_accuracy: 0.9222 - lr: 1.0000\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5961 - accuracy: 0.9253 - val_loss: 0.5185 - val_accuracy: 0.9208 - lr: 1.0000\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5948 - accuracy: 0.9249 - val_loss: 0.5091 - val_accuracy: 0.9232 - lr: 1.0000\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5923 - accuracy: 0.9243 - val_loss: 0.5103 - val_accuracy: 0.9269 - lr: 1.0000\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5855 - accuracy: 0.9241 - val_loss: 0.5159 - val_accuracy: 0.9218 - lr: 1.0000\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5840 - accuracy: 0.9283 - val_loss: 0.5028 - val_accuracy: 0.9269 - lr: 1.0000\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5831 - accuracy: 0.9260 - val_loss: 0.5001 - val_accuracy: 0.9259 - lr: 1.0000\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5759 - accuracy: 0.9274 - val_loss: 0.5061 - val_accuracy: 0.9181 - lr: 1.0000\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5753 - accuracy: 0.9241 - val_loss: 0.5147 - val_accuracy: 0.9208 - lr: 1.0000\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5697 - accuracy: 0.9293 - val_loss: 0.4977 - val_accuracy: 0.9264 - lr: 1.0000\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5711 - accuracy: 0.9286 - val_loss: 0.5046 - val_accuracy: 0.9191 - lr: 1.0000\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5621 - accuracy: 0.9297 - val_loss: 0.5179 - val_accuracy: 0.9174 - lr: 1.0000\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5713 - accuracy: 0.9300 - val_loss: 0.5061 - val_accuracy: 0.9220 - lr: 1.0000\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5659 - accuracy: 0.9301 - val_loss: 0.4966 - val_accuracy: 0.9269 - lr: 1.0000\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5594 - accuracy: 0.9283 - val_loss: 0.4995 - val_accuracy: 0.9252 - lr: 1.0000\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 13s 90ms/step - loss: 0.5611 - accuracy: 0.9269 - val_loss: 0.4993 - val_accuracy: 0.9230 - lr: 1.0000\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5549 - accuracy: 0.9293 - val_loss: 0.4955 - val_accuracy: 0.9215 - lr: 1.0000\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5549 - accuracy: 0.9304 - val_loss: 0.5006 - val_accuracy: 0.9208 - lr: 1.0000\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5483 - accuracy: 0.9324 - val_loss: 0.5089 - val_accuracy: 0.9183 - lr: 1.0000\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5699 - accuracy: 0.9274 - val_loss: 0.4900 - val_accuracy: 0.9242 - lr: 1.0000\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5532 - accuracy: 0.9297 - val_loss: 0.4906 - val_accuracy: 0.9247 - lr: 1.0000\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5516 - accuracy: 0.9287 - val_loss: 0.4918 - val_accuracy: 0.9218 - lr: 1.0000\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5458 - accuracy: 0.9293 - val_loss: 0.5002 - val_accuracy: 0.9242 - lr: 1.0000\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5422 - accuracy: 0.9322 - val_loss: 0.4861 - val_accuracy: 0.9259 - lr: 1.0000\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5406 - accuracy: 0.9314 - val_loss: 0.4910 - val_accuracy: 0.9225 - lr: 1.0000\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5415 - accuracy: 0.9316 - val_loss: 0.4810 - val_accuracy: 0.9269 - lr: 1.0000\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5404 - accuracy: 0.9328 - val_loss: 0.4842 - val_accuracy: 0.9254 - lr: 1.0000\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5456 - accuracy: 0.9285 - val_loss: 0.4904 - val_accuracy: 0.9218 - lr: 1.0000\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5418 - accuracy: 0.9302 - val_loss: 0.4890 - val_accuracy: 0.9225 - lr: 1.0000\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5350 - accuracy: 0.9329 - val_loss: 0.4870 - val_accuracy: 0.9247 - lr: 1.0000\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.9332\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5386 - accuracy: 0.9332 - val_loss: 0.4979 - val_accuracy: 0.9222 - lr: 1.0000\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5339 - accuracy: 0.9323 - val_loss: 0.4976 - val_accuracy: 0.9222 - lr: 0.0000e+00\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 13s 88ms/step - loss: 0.5336 - accuracy: 0.9312 - val_loss: 0.4928 - val_accuracy: 0.9235 - lr: 0.0000e+00\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5364 - accuracy: 0.9296 - val_loss: 0.4974 - val_accuracy: 0.9227 - lr: 0.0000e+00\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5353 - accuracy: 0.9333 - val_loss: 0.4963 - val_accuracy: 0.9230 - lr: 0.0000e+00\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5331 - accuracy: 0.9348 - val_loss: 0.4945 - val_accuracy: 0.9222 - lr: 0.0000e+00\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 13s 88ms/step - loss: 0.5378 - accuracy: 0.9322 - val_loss: 0.4954 - val_accuracy: 0.9227 - lr: 0.0000e+00\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5380 - accuracy: 0.9317 - val_loss: 0.4958 - val_accuracy: 0.9225 - lr: 0.0000e+00\n",
      "Epoch 00060: early stopping\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=classWeight,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Графіки тренування моделі\n",
    "plt.figure()\n",
    "plt.plot(H.history['loss'], label='train_loss')\n",
    "plt.plot(H.history['val_loss'], label='val_loss')\n",
    "plt.plot(H.history['accuracy'], label='train_acc')\n",
    "plt.plot(H.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Ukrainian_OCR_tf_2.1_lower_case.h5',save_format=\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('Ukrainian_OCR_tf_2.1_corrected_lower_case.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           а       0.99      0.93      0.96        92\n",
      "           б       1.00      0.97      0.98        91\n",
      "           в       0.99      1.00      0.99        91\n",
      "           г       0.99      0.99      0.99        91\n",
      "           ґ       0.97      0.99      0.98        91\n",
      "           д       0.98      0.96      0.97        91\n",
      "           е       0.97      0.97      0.97        91\n",
      "           є       1.00      0.97      0.98        91\n",
      "           ж       1.00      1.00      1.00        91\n",
      "           з       0.85      0.84      0.84        91\n",
      "           и       0.84      0.97      0.90        91\n",
      "           і       0.72      0.89      0.80        91\n",
      "           ї       0.87      0.67      0.76        92\n",
      "           й       1.00      0.79      0.88        91\n",
      "           к       1.00      0.98      0.99        90\n",
      "           л       0.98      1.00      0.99        91\n",
      "           м       0.97      1.00      0.98        90\n",
      "           н       0.98      1.00      0.99        91\n",
      "           о       0.91      0.66      0.76        91\n",
      "           п       0.99      0.99      0.99        91\n",
      "           р       0.99      1.00      0.99        91\n",
      "           с       0.98      0.98      0.98        91\n",
      "           т       1.00      0.93      0.97        91\n",
      "           у       0.98      0.99      0.98        90\n",
      "           ф       1.00      0.98      0.99        91\n",
      "           х       1.00      0.99      0.99        91\n",
      "           ц       0.98      0.98      0.98        91\n",
      "           ч       1.00      0.99      0.99        91\n",
      "           ш       0.99      1.00      0.99        92\n",
      "           щ       1.00      0.97      0.98        92\n",
      "           ь       1.00      0.99      0.99        91\n",
      "           ю       1.00      0.99      0.99        91\n",
      "           я       0.98      0.98      0.98        91\n",
      "           1       0.95      0.89      0.92        46\n",
      "           2       1.00      0.98      0.99        46\n",
      "           3       0.70      0.72      0.71        46\n",
      "           4       1.00      0.98      0.99        45\n",
      "           5       1.00      1.00      1.00        45\n",
      "           6       1.00      1.00      1.00        46\n",
      "           7       1.00      0.98      0.99        45\n",
      "           8       1.00      0.96      0.98        45\n",
      "           9       0.98      1.00      0.99        45\n",
      "           0       0.56      0.93      0.70        45\n",
      "           №       1.00      0.89      0.94        44\n",
      "           %       1.00      1.00      1.00        45\n",
      "           @       1.00      0.96      0.98        45\n",
      "           ,       0.46      0.63      0.53        46\n",
      "           .       0.12      0.02      0.04        46\n",
      "           ?       0.98      0.98      0.98        46\n",
      "           :       0.45      0.96      0.61        46\n",
      "           ;       0.23      0.07      0.10        46\n",
      "           \"       0.90      0.64      0.75        44\n",
      "           !       0.83      0.96      0.89        45\n",
      "           (       1.00      0.98      0.99        45\n",
      "           )       1.00      1.00      1.00        45\n",
      "           -       0.85      1.00      0.92        45\n",
      "           '       0.53      0.93      0.68        44\n",
      "\n",
      "    accuracy                           0.92      4090\n",
      "   macro avg       0.90      0.91      0.90      4090\n",
      "weighted avg       0.93      0.92      0.92      4090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# define the list of label names\n",
    "\n",
    "labelNames = \"абвгґдеєжзиіїйклмнопрстуфхцчшщьюя1234567890№%@,.?:;\\\"!()-'\"\n",
    "labelNames = [l for l in labelNames]\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import build_montages\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "images = []\n",
    "# randomly select a few testing characters\n",
    "\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(66,)):\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    "    output += label\n",
    "    image = (testX[i] * 255).astype(\"uint8\")\n",
    "    color = (0, 255, 0)\n",
    "    color = (0, 0, 255)\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    img_pil = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=34)\n",
    "    draw.text((5, 20), label, font=font, fill=color)\n",
    "    image = np.array(img_pil)\n",
    "    images.append(image)\n",
    "  \n",
    "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
    "cv2.imshow('q',montage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'гЛЄРНезцХВЙжЮЕйткЗПццЗнТчХЧСрОРаФЬЩҐтИЖйИАОтЯмрЛЩ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
