{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('Ukrainian_OCR_tf_2.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373168"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('Ukrainian_OCR_tf_2.1.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset(datasetPath):\n",
    "\n",
    "  # List for storing data\n",
    "  data = []\n",
    "  \n",
    "  # List for storing labels\n",
    "  labels = []\n",
    "  \n",
    "  for row in open(datasetPath): #Openfile and start reading each row\n",
    "    #Split the row at every comma\n",
    "    row = row.split(\",\")\n",
    "    \n",
    "    #row[0] contains label\n",
    "    label = int(row[0])\n",
    "    \n",
    "    #Other all collumns contains pixel values make a saperate array for that\n",
    "    image = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
    "    \n",
    "    #Reshaping image to 28 x 28 pixels\n",
    "    image = image.reshape((32, 32))\n",
    "    \n",
    "    #append image to data\n",
    "    data.append(image)\n",
    "    \n",
    "    #append label to labels\n",
    "    labels.append(label)\n",
    "    \n",
    "  #Converting data to numpy array of type float32\n",
    "  data = np.array(data, dtype='float32')\n",
    "  \n",
    "  #Converting labels to type int\n",
    "  labels = np.array(labels, dtype=\"int\")\n",
    "  \n",
    "  return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_predictions(interpreter, input, output, batch):\n",
    "  interpreter.set_tensor(input[0]['index'], batch)\n",
    "  interpreter.invoke()\n",
    "  predictions = interpreter.get_tensor(output[0]['index'])\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Data, Labels) = load_dataset(\"../data/uaset_extended_lower_case.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Each image in the A-Z and MNIST digts datasets are 28x28 pixels;\n",
    "# However, the architecture we're using is designed for 32x32 images,\n",
    "# So we need to resize them to 32x32\n",
    "\n",
    "Data = [cv2.resize(image, (32, 32)) for image in Data]\n",
    "Data = np.array(Data, dtype=\"float32\")\n",
    "\n",
    "# add a channel dimension to every image in the dataset and scale the\n",
    "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
    "\n",
    "Data = np.expand_dims(Data, axis=-1)\n",
    "Data /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "le = LabelBinarizer()\n",
    "Labels = le.fit_transform(Labels)\n",
    "\n",
    "counts = Labels.sum(axis=0)\n",
    "\n",
    "# account for skew in the labeled data\n",
    "classTotals = Labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "  classWeight[i] = classTotals.max() / classTotals[i]\n",
    "  \n",
    "(trainX, testX, trainY, testY) = train_test_split(Data,\n",
    "\tLabels, test_size=0.95, stratify=Labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorFlow Lite model from file\n",
    "interpreter = tf.lite.Interpreter(model_path=\"Ukrainian_OCR.tflite\")\n",
    "interpreter.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 89, does not match size of target_names, 90. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     predictions\u001b[39m.\u001b[39mappend(batch_pre)\n\u001b[0;32m     15\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(predictions)\n\u001b[1;32m---> 16\u001b[0m \u001b[39mprint\u001b[39m(classification_report(testY\u001b[39m.\u001b[39;49margmax(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m     17\u001b[0m \tpredictions\u001b[39m.\u001b[39;49margmax(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), target_names\u001b[39m=\u001b[39;49mlabelNames))\n",
      "File \u001b[1;32md:\\programming\\miniconda\\envs\\DeepLearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2327\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlabels size, \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m, does not match size of target_names, \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2328\u001b[0m                 \u001b[39mlen\u001b[39m(labels), \u001b[39mlen\u001b[39m(target_names)\n\u001b[0;32m   2329\u001b[0m             )\n\u001b[0;32m   2330\u001b[0m         )\n\u001b[0;32m   2331\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2332\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2333\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNumber of classes, \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m, does not match size of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2334\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtarget_names, \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m. Try specifying the labels \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2335\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mparameter\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(labels), \u001b[39mlen\u001b[39m(target_names))\n\u001b[0;32m   2336\u001b[0m         )\n\u001b[0;32m   2337\u001b[0m \u001b[39mif\u001b[39;00m target_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2338\u001b[0m     target_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m l \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 89, does not match size of target_names, 90. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# define the list of label names\n",
    "\n",
    "alphabet = list('абвгґдеєжзиіїйклмнопрстуфхцчшщьюя1234567890№%@,.?:;\"!()-\\'АБВГҐДЕЄЖЗИІЇЙКЛМНОПРСТУФХЦЧШЩЬЮЯ')\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = []\n",
    "for i in range(0, len(testX), BS):\n",
    "    batch = testX[i:i + BS]\n",
    "    batch_pre = get_batch_predictions(interpreter, input_details, output_details, batch)\n",
    "    predictions.append(batch_pre)\n",
    "\n",
    "predictions = np.vstack(predictions)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import build_montages\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "output = \"\"\n",
    "images = []\n",
    "# randomly select a few testing characters\n",
    "\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(66,)):\n",
    "    \n",
    "    batch = testX[i][np.newaxis, ...]\n",
    "    batch_pre = get_batch_predictions(interpreter, input_details, output_details, batch)\n",
    "    prediction = batch_pre.argmax(axis=1)\n",
    "    \n",
    "    label = labelNames[prediction[0]]\n",
    "    output += label\n",
    "    image = (testX[i] * 255).astype(\"uint8\")\n",
    "    color = (0, 255, 0)\n",
    "    color = (0, 0, 255)\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    img_pil = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=34)\n",
    "    draw.text((5, 20), label, font=font, fill=color)\n",
    "    image = np.array(img_pil)\n",
    "    images.append(image)\n",
    "  \n",
    "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
    "cv2.imshow('q',montage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!Фгш-тЄЬопгпТУ.-в!ШПО\"ЇчЖй7ТВ(ОПгіі1ьґк8:\\'кВЯцт-ЇШМВх№фкьиТіфшю(Ри'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
